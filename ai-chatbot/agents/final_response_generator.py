"""
Final Response Generator - ì „ëµ ê¸°ë°˜ ì™„ë²½í•œ ë©´ì ‘ ë‹µë³€ ìƒì„±

ì—­í• :
1. Data Integratorê°€ ì„¤ê³„í•œ ë‹µë³€ ì „ëµì„ ë°›ì•„ ì‹¤í–‰
2. í† ìŠ¤ ì±„ìš©ê³µê³  + ì „ëµ + ì›ë³¸ ë°ì´í„° â†’ ì™„ë²½í•œ ë©´ì ‘ ë‹µë³€ ìƒì„±
3. í† ìŠ¤ ë¬¸í™”ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ ë‹µë³€
4. êµ¬ì²´ì  ì„±ê³¼ì™€ ìˆ«ì í¬í•¨, ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ê°•ì¡°
"""

import json
from typing import Dict, Any
from workflow.state import PortfolioState
from config.settings import Config
from utils.openai_client import get_openai_client

class FinalResponseGenerator:
    """ì „ëµ ê¸°ë°˜ ì™„ë²½í•œ ë©´ì ‘ ë‹µë³€ ìƒì„± ì—ì´ì „íŠ¸"""
    
    async def generate(self, state: PortfolioState) -> PortfolioState:
        """Data Integrator ì „ëµì„ ë°›ì•„ ì™„ë²½í•œ í† ìŠ¤ ë©´ì ‘ ë‹µë³€ ìƒì„±"""
        
        print("\nğŸ’¬ Final Response Generator (ì „ëµ ê¸°ë°˜ ë‹µë³€ ìƒì„±) ì‹œì‘")
        
        # 1. Data Integrator ì „ëµ í™•ì¸
        strategy = state.integrated_data
        if not strategy:
            print("   âš ï¸ Data Integrator ì „ëµ ì—†ìŒ - ê¸°ë³¸ ë‹µë³€ ìƒì„±")
            final_answer = self._generate_fallback_answer(state)
        else:
            print(f"   ğŸ“‹ ë‹µë³€ ì „ëµ: {strategy.get('answer_strategy', 'N/A')[:50]}...")
            
            # 2. ì „ëµ ê¸°ë°˜ ì™„ë²½í•œ ë‹µë³€ ìƒì„±
            final_answer = await self._generate_strategic_answer(state, strategy)
        
        # 3. Stateì— ìµœì¢… ë‹µë³€ ì €ì¥
        state.response = final_answer
        
        # 4. ì¶”ì²œ ë§í¬ ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        links = self._generate_links(state, strategy.get('raw_data', {}))
        state.recommended_links = links
        
        # 5. í’ˆì§ˆ í‰ê°€
        quality_score = self._evaluate_response_quality(final_answer, state)
        state.response_quality_score = quality_score
        
        print(f"   âœ… ì™„ë²½í•œ ë©´ì ‘ ë‹µë³€ ìƒì„± ì™„ë£Œ")
        print(f"   ğŸ“ ë‹µë³€ ê¸¸ì´: {len(final_answer)}ì")
        print(f"   ğŸ”— ì¶”ì²œ ë§í¬: {len(links)}ê°œ")
        print(f"   ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}")
        
        return state
    
    async def _generate_strategic_answer(self, state: PortfolioState, strategy: Dict[str, Any]) -> str:
        """Data Integrator ì „ëµì„ ê¸°ë°˜ìœ¼ë¡œ ì™„ë²½í•œ ë‹µë³€ ìƒì„±"""
        
        try:
            client = get_openai_client()
            
            # í† ìŠ¤ ì±„ìš©ê³µê³  ì „ì²´ ì»¨í…ìŠ¤íŠ¸
            toss_context = Config.get_toss_job_context()
            
            # ì „ëµ ë°ì´í„° í¬ë§·íŒ…
            strategy_summary = self._format_strategy_for_gpt(strategy)
            
            # ì›ë³¸ ë°ì´í„° í¬ë§·íŒ…
            raw_data_summary = self._format_raw_data(strategy.get('raw_data', {}))
            
            prompt = f"""
{toss_context}

ë©´ì ‘ ì§ˆë¬¸: "{state.question}"

Data Integratorê°€ ì„¤ê³„í•œ ì™„ë²½í•œ ë‹µë³€ ì „ëµ:
{strategy_summary}

í™œìš©í•  í™©ì¤€í˜¸ì˜ ì›ë³¸ ë°ì´í„°:
{raw_data_summary}

GPT ì„ë¬´ - ì™„ë²½í•œ í† ìŠ¤ ë©´ì ‘ ë‹µë³€ ìƒì„±:
1. ìœ„ ì „ëµì„ ì •í™•íˆ ë”°ë¼ ìì—°ìŠ¤ëŸ¬ìš´ ë©´ì ‘ ë‹µë³€ ìƒì„±
2. í† ìŠ¤ ì±„ìš©ë‹´ë‹¹ìê°€ ë“£ê³  ì‹¶ì–´í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±
3. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í•µì‹¬ìœ¼ë¡œ ê°•ì¡°
4. êµ¬ì²´ì  ìˆ«ì, ì„±ê³¼, ê¸°ìˆ ì  ê¹Šì´ í¬í•¨
5. í† ìŠ¤ ë¬¸í™”ì— ë§ëŠ” ìì‹ ê° ìˆê³  êµ¬ì²´ì ì¸ í†¤

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
- ê¸¸ì´: 150-250ë‹¨ì–´ (ë©´ì ‘ ë‹µë³€ ì ì • ê¸¸ì´)
- êµ¬ì¡°: {strategy.get('response_structure', 'ë„ì… â†’ ê²½í—˜ â†’ ì„±ê³¼ â†’ ê¸°ì—¬')}
- í†¤: {strategy.get('tone_style', 'êµ¬ì²´ì ì´ê³  ìì‹ ê° ìˆëŠ” í†¤')}
- í•µì‹¬ í¬ì¸íŠ¸: {', '.join(strategy.get('key_points', []))}
- ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸: {strategy.get('business_impact_focus', '')}

í† ìŠ¤ ë©´ì ‘ê´€ì—ê²Œ í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ì€ ì œì™¸í•˜ê³  ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”.
"""

            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í† ìŠ¤ ML Engineer ë©´ì ‘ì„ ìœ„í•œ ì™„ë²½í•œ ë‹µë³€ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Data Integratorì˜ ì „ëµì„ ì •í™•íˆ ë”°ë¼ í† ìŠ¤ ë©´ì ‘ê´€ì´ ì›í•˜ëŠ” ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.7,
                max_tokens=1200
            )
            
            generated_answer = response.choices[0].message.content.strip()
            print(f"   ğŸ¤– GPT ë‹µë³€ ìƒì„±: {generated_answer[:80]}...")
            
            return generated_answer
            
        except Exception as e:
            print(f"   âŒ ì „ëµ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return self._generate_fallback_answer(state)
    
    def _format_strategy_for_gpt(self, strategy: Dict[str, Any]) -> str:
        """ì „ëµ ë°ì´í„°ë¥¼ GPTê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        
        formatted = ""
        
        # í•µì‹¬ ì „ëµ í•„ë“œë“¤ë§Œ ì„ ë³„
        key_fields = [
            'answer_strategy', 'response_structure', 'key_points',
            'problem_solving_angle', 'business_impact_focus', 
            'toss_connection', 'tone_style', 'evidence_usage'
        ]
        
        for field in key_fields:
            if field in strategy:
                value = strategy[field]
                if isinstance(value, list):
                    formatted += f"{field}: {', '.join(value)}\n"
                else:
                    formatted += f"{field}: {value}\n"
        
        return formatted if formatted else "ì „ëµ ë°ì´í„°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _format_raw_data(self, raw_data: Dict[str, Any]) -> str:
        """ì›ë³¸ ë°ì´í„°ë¥¼ ìš”ì•½ í¬ë§·íŒ…"""
        
        if not raw_data:
            return "ì›ë³¸ ë°ì´í„° ì—†ìŒ"
        
        formatted = ""
        for data_type, data_content in raw_data.items():
            if data_content:
                formatted += f"\n=== {data_type} ===\n"
                if isinstance(data_content, dict):
                    # í•µì‹¬ í•„ë“œë§Œ ìš”ì•½
                    for key, value in data_content.items():
                        if isinstance(value, (str, int, float)) and len(str(value)) < 100:
                            formatted += f"- {key}: {value}\n"
                else:
                    formatted += f"- ë‚´ìš©: {str(data_content)[:100]}\n"
        
        return formatted if formatted else "ì›ë³¸ ë°ì´í„°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _generate_fallback_answer(self, state: PortfolioState) -> str:
        """ì „ëµ ì—†ì´ ê¸°ë³¸ ë‹µë³€ ìƒì„±"""
        
        return f"""ì£„ì†¡í•©ë‹ˆë‹¤. '{state.question}' ì§ˆë¬¸ì— ëŒ€í•œ ìƒì„¸í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. 

ì œê°€ í† ìŠ¤ ML Engineer ì§ë¬´ì— ì§€ì›í•œ ì´ìœ ëŠ” AI/ML ê¸°ìˆ ë¡œ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ ë‚´ê³  ì‹¶ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. íŠ¹íˆ LLM/RAG ê¸°ìˆ ê³¼ ì¶”ì²œì‹œìŠ¤í…œ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í† ìŠ¤ì˜ ë‹¤ì–‘í•œ AI í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.

êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ì„±ê³¼ì— ëŒ€í•´ì„œëŠ” ë³„ë„ë¡œ ìƒì„¸íˆ ë§ì”€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    
    def _generate_links(self, state: PortfolioState, raw_data: Dict[str, Any]) -> Dict[str, str]:
        """ê´€ë ¨ í¬íŠ¸í´ë¦¬ì˜¤ ë§í¬ ìƒì„±"""
        
        links = {}
        
        if not raw_data:
            return links
        
        # í”„ë¡œì íŠ¸ ë§í¬
        for key in raw_data.keys():
            if "project_data" in key:
                # project_dataì—ì„œ í”„ë¡œì íŠ¸ëª… ì¶”ì¶œ
                if isinstance(raw_data[key], dict):
                    for project_key in raw_data[key].keys():
                        if project_key in Config.COMPLETE_PROJECTS:
                            links[f"{project_key} í”„ë¡œì íŠ¸"] = f"/projects/{project_key}"
        
        # ìŠ¤í‚¬ ë§í¬ (ìµœëŒ€ 3ê°œ)
        skill_count = 0
        for key in raw_data.keys():
            if "skill_data" in key and skill_count < 3:
                if isinstance(raw_data[key], dict):
                    for skill_key in raw_data[key].keys():
                        if skill_key in Config.COMPLETE_LLM_SKILLS and skill_count < 3:
                            links[f"{skill_key} ìŠ¤í‚¬"] = f"/skills/{skill_key}"
                            skill_count += 1
        
        return links
    
    def _evaluate_response_quality(self, answer: str, state: PortfolioState) -> float:
        """ë‹µë³€ í’ˆì§ˆ í‰ê°€"""
        
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ê¸¸ì´ ì²´í¬ (ì ì • ë²”ìœ„: 150-300ì)
        length = len(answer)
        if 150 <= length <= 300:
            score += 0.2
        elif 100 <= length < 150 or 300 < length <= 400:
            score += 0.1
        
        # í† ìŠ¤ ê´€ë ¨ ì–¸ê¸‰
        toss_keywords = ["í† ìŠ¤", "toss", "ë¹„ì¦ˆë‹ˆìŠ¤", "ì„íŒ©íŠ¸", "ì„œë¹„ìŠ¤"]
        toss_mentions = sum(1 for keyword in toss_keywords if keyword in answer.lower())
        score += min(toss_mentions * 0.05, 0.15)
        
        # êµ¬ì²´ì  ë‚´ìš© (ìˆ«ì, ì„±ê³¼ ì§€í‘œ)
        concrete_keywords = ["í”„ë¡œì íŠ¸", "%", "ê°œì„ ", "êµ¬í˜„", "ê²½í—˜", "ì„±ê³¼"]
        concrete_mentions = sum(1 for keyword in concrete_keywords if keyword in answer)
        score += min(concrete_mentions * 0.05, 0.15)
        
        return min(score, 1.0)


async def final_response_generator_agent(state: PortfolioState) -> PortfolioState:
    """ì „ëµ ê¸°ë°˜ ì™„ë²½í•œ ë©´ì ‘ ë‹µë³€ ìƒì„± ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    
    generator = FinalResponseGenerator()
    return await generator.generate(state)