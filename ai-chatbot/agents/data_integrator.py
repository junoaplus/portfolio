"""
Data Integrator Agent - GPT ê¸°ë°˜ ì™„ì „ ë°ì´í„° í†µí•©

ì—­í• :
1. Routerê°€ ì„ íƒí•œ Nê°œ ë°ì´í„°(1~4ê°œ)ë¥¼ GPTë¡œ ì™„ì „ í†µí•©
2. í† ìŠ¤ ì±„ìš©ê³µê³  + ì§ˆë¬¸ + ì„ íƒëœ ë°ì´í„° â†’ í•˜ë‚˜ì˜ ì¼ê´€ëœ ìŠ¤í† ë¦¬
3. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ì¤‘ì‹¬ìœ¼ë¡œ ì¬êµ¬ì„± (ìš”ì¦˜ ê°€ì¥ ì¤‘ìš”í•œ ì—­ëŸ‰)
4. í† ìŠ¤ 6ê°œ ì—…ë¬´ì˜ì—­ê³¼ ì§ˆë¬¸ ì™„ë²½ ë§¤í•‘
5. ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ê°•ì¡°í•œ ì „ëµì  í†µí•©
"""

import json
from typing import Dict, Any
from workflow.state import PortfolioState
from config.settings import Config
from utils.openai_client import get_openai_client

class DataIntegratorAgent:
    """GPT ê¸°ë°˜ ì™„ì „ ë°ì´í„° í†µí•© ì—ì´ì „íŠ¸"""
    
    async def integrate(self, state: PortfolioState) -> PortfolioState:
        """Routerê°€ ì„ íƒí•œ Nê°œ ë°ì´í„°ë¥¼ GPTë¡œ ì™„ì „ í†µí•©"""
        
        print("\nğŸ”§ Data Integrator (GPT ê¸°ë°˜ ì™„ì „ í†µí•©) ì‹œì‘")
        
        # 1. ì„ íƒëœ ë°ì´í„° í™•ì¸
        selected_data = state.extracted_data
        data_count = len(selected_data)
        
        print(f"   ğŸ“Š Router ì„ íƒ ë°ì´í„°: {data_count}ê°œ")
        for key in selected_data.keys():
            print(f"   - {key}")
        
        # 2. GPTë¡œ ì™„ì „ í†µí•©
        if data_count > 0:
            integrated_result = await self._gpt_complete_integration(state, selected_data)
        else:
            print("   âš ï¸ ì„ íƒëœ ë°ì´í„° ì—†ìŒ - ê¸°ë³¸ ì²˜ë¦¬")
            integrated_result = self._get_fallback_integration(state)
        
        # 3. Stateì— í†µí•© ê²°ê³¼ ì €ì¥
        state.integrated_data = integrated_result
        
        print(f"   âœ… GPT ë‹µë³€ ì „ëµ ì„¤ê³„ ì™„ë£Œ")
        print(f"   ğŸ¯ ë‹µë³€ ì „ëµ: {integrated_result.get('answer_strategy', 'N/A')[:50]}...")
        print(f"   ğŸ”§ ë‹µë³€ êµ¬ì¡°: {integrated_result.get('response_structure', 'N/A')[:50]}...")
        
        return state
    
    async def _gpt_complete_integration(self, state: PortfolioState, selected_data: Dict[str, Any]) -> Dict[str, Any]:
        """GPTë¡œ ì„ íƒëœ ë°ì´í„°ë“¤ì„ ì™„ì „ í†µí•©"""
        
        try:
            client = get_openai_client()
            
            # í† ìŠ¤ ì±„ìš©ê³µê³  ì „ì²´ ì»¨í…ìŠ¤íŠ¸
            toss_context = Config.get_toss_job_context()
            
            # ì„ íƒëœ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì •ë¦¬
            data_summary = self._format_selected_data(selected_data)
            
            prompt = f"""
{toss_context}

ë©´ì ‘ ì§ˆë¬¸: "{state.question}"

Routerê°€ ì´ ì§ˆë¬¸ì— í•„ìš”í•˜ë‹¤ê³  ì„ íƒí•œ í™©ì¤€í˜¸ì˜ ë°ì´í„°ë“¤:
{data_summary}

GPT ì„ë¬´ - ì™„ë²½í•œ ë©´ì ‘ ë‹µë³€ ì „ëµ ì„¤ê³„:
1. í† ìŠ¤ ML Engineer ì±„ìš©ê³µê³ ì™€ ë©´ì ‘ ì§ˆë¬¸ì„ ì •í™•íˆ ë§¤í•‘ ë¶„ì„
2. ì„ íƒëœ ë°ì´í„°ë“¤ì„ í•˜ë‚˜ì˜ ì™„ì „í•œ ìŠ¤í† ë¦¬ë¡œ í†µí•©
3. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í•µì‹¬ìœ¼ë¡œ ê°•ì¡° (ìš”ì¦˜ ê°€ì¥ ì¤‘ìš”í•œ ì—­ëŸ‰)
4. í† ìŠ¤ê°€ ì›í•˜ëŠ” í¬ì¸íŠ¸(AI/ML, ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸, ë¹…ë°ì´í„°)ì™€ ì§ˆë¬¸ ì˜ë„ë¥¼ ì™„ë²½ ì—°ê²°
5. Response Generatorê°€ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì™„ë²½í•œ ë‹µë³€ ì „ëµ ì œê³µ

í† ìŠ¤ ì±„ìš©ë‹´ë‹¹ì ê´€ì ì—ì„œ ë¶„ì„:
- ì´ ì§ˆë¬¸ìœ¼ë¡œ ë¬´ì—‡ì„ í™•ì¸í•˜ë ¤ í•˜ëŠ”ê°€?
- í™©ì¤€í˜¸ì˜ ì–´ë–¤ ê²½í—˜ì´ í† ìŠ¤ ìš”êµ¬ì‚¬í•­ì— ê°€ì¥ ë¶€í•©í•˜ëŠ”ê°€?
- ë¬¸ì œ ì •ì˜ë¶€í„° í•´ê²°ê¹Œì§€ ì£¼ë„ì  ê¸°ì—¬ ì–´ë–»ê²Œ ì–´í•„í• ê¹Œ?
- ë‹µë³€ êµ¬ì¡°ì™€ íë¦„ì„ ì–´ë–»ê²Œ ì§œì•¼ ê°€ì¥ ì„íŒ©íŠ¸ ìˆì„ê¹Œ?

ë‹¤ìŒ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "answer_strategy": "ì´ ì§ˆë¬¸ì— ëŒ€í•œ í† ìŠ¤ ë§ì¶¤ ì™„ë²½í•œ ë‹µë³€ ì „ëµê³¼ ì ‘ê·¼ë²•",
  "response_structure": "ë„ì…ë¶€ â†’ ê²½í—˜ ì„¤ëª… â†’ ì„±ê³¼ ê°•ì¡° â†’ í† ìŠ¤ ê¸°ì—¬ ìˆœì„œì˜ êµ¬ì²´ì  êµ¬ì¡°",
  "key_points": ["ë‹µë³€ì—ì„œ ë°˜ë“œì‹œ ê°•ì¡°í•´ì•¼ í•  í•µì‹¬ í¬ì¸íŠ¸ë“¤"],
  "problem_solving_angle": "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ì–´ë–»ê²Œ ë¶€ê°ì‹œí‚¬ì§€ êµ¬ì²´ì  ë°©ë²•",
  "business_impact_focus": "ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ ì–´ë–»ê²Œ ì–´í•„í• ì§€",
  "toss_connection": "í† ìŠ¤ 6ê°œ ì—…ë¬´ì˜ì—­ê³¼ ì–´ë–»ê²Œ ì—°ê²°í• ì§€",
  "tone_style": "í† ìŠ¤ ë¬¸í™”ì— ë§ëŠ” ë‹µë³€ í†¤ê³¼ ìŠ¤íƒ€ì¼",
  "evidence_usage": "ì„ íƒëœ ë°ì´í„°ë¥¼ ë‹µë³€ì—ì„œ ì–´ë–»ê²Œ í™œìš©í• ì§€"
}}
"""

            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í† ìŠ¤ ML Engineer ë©´ì ‘ ì „ëµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í›„ë³´ìì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì„œ Response Generatorê°€ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì™„ë²½í•œ ë‹µë³€ ì „ëµì„ ì„¤ê³„í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.3,
                max_tokens=1500
            )
            
            gpt_response = response.choices[0].message.content.strip()
            print(f"   ğŸ¤– GPT í†µí•© ë¶„ì„: {gpt_response[:100]}...")
            
            # JSON íŒŒì‹±
            try:
                integration_result = json.loads(gpt_response)
                
                # ì›ë³¸ ë°ì´í„°ë„ í¬í•¨ (Response Generatorê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ)
                integration_result["raw_data"] = selected_data
                
                return integration_result
                
            except json.JSONDecodeError:
                print(f"   âŒ GPT JSON íŒŒì‹± ì‹¤íŒ¨: {gpt_response}")
                return self._get_fallback_integration(state)
            
        except Exception as e:
            print(f"   âŒ GPT í†µí•© ì‹¤íŒ¨: {str(e)}")
            return self._get_fallback_integration(state)
    
    def _format_selected_data(self, selected_data: Dict[str, Any]) -> str:
        """ì„ íƒëœ ë°ì´í„°ë¥¼ GPTê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        
        formatted = ""
        
        for data_type, data_content in selected_data.items():
            if not data_content:
                continue
                
            formatted += f"\n=== {data_type} ===\n"
            
            if isinstance(data_content, dict):
                # dict í˜•íƒœì˜ ë°ì´í„° ì²˜ë¦¬
                for key, value in data_content.items():
                    if isinstance(value, (str, int, float)):
                        formatted += f"{key}: {value}\n"
                    elif isinstance(value, list):
                        formatted += f"{key}: {', '.join(map(str, value))}\n"
                    elif isinstance(value, dict):
                        formatted += f"{key}:\n"
                        for sub_key, sub_value in value.items():
                            formatted += f"  - {sub_key}: {sub_value}\n"
                    else:
                        formatted += f"{key}: {str(value)}\n"
            else:
                formatted += f"ë‚´ìš©: {str(data_content)}\n"
        
        return formatted if formatted else "ì„ íƒëœ ë°ì´í„°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _get_fallback_integration(self, state: PortfolioState) -> Dict[str, Any]:
        """GPT í†µí•© ì‹¤íŒ¨ì‹œ ê¸°ë³¸ í†µí•© ë°ì´í„°"""
        
        return {
            "answer_strategy": f"'{state.question}' ì§ˆë¬¸ì— ëŒ€í•œ í† ìŠ¤ ë§ì¶¤ ë‹µë³€ ì „ëµ: í™©ì¤€í˜¸ì˜ ê²½í—˜ê³¼ ì—­ëŸ‰ì„ í† ìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ì¶° ì¢…í•© ì œì‹œ",
            "response_structure": "ë„ì…ë¶€(ì§ˆë¬¸ ì´í•´) â†’ êµ¬ì²´ì  ê²½í—˜ ì„¤ëª… â†’ ì„±ê³¼ì™€ ì„íŒ©íŠ¸ ê°•ì¡° â†’ í† ìŠ¤ì—ì„œì˜ ê¸°ì—¬ ë°©ì•ˆ",
            "key_points": ["ë¬¸ì œ í•´ê²° ê²½í—˜", "ê¸°ìˆ ì  ê¹Šì´", "ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸", "í† ìŠ¤ ì í•©ì„±"],
            "problem_solving_angle": "ë³µì¡í•œ ë¬¸ì œë¥¼ ì •ì˜í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•œ ì£¼ë„ì  ê²½í—˜ ë¶€ê°",
            "business_impact_focus": "ì‹¤ì œ ì„œë¹„ìŠ¤ ì„±ëŠ¥ ê°œì„ ê³¼ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒì— ì§‘ì¤‘",
            "toss_connection": "AI/ML ì˜ì—­ì˜ LLM/RAG ê¸°ìˆ ê³¼ ì¶”ì²œì‹œìŠ¤í…œ ê²½í—˜ìœ¼ë¡œ í† ìŠ¤ ìš”êµ¬ì‚¬í•­ì— ì§ì ‘ ë¶€í•©",
            "tone_style": "êµ¬ì²´ì ì´ê³  ìì‹ ê° ìˆëŠ” í†¤, ìˆ«ìì™€ ì„±ê³¼ ì¤‘ì‹¬ì˜ íŒ©íŠ¸ ê¸°ë°˜ ì„¤ëª…",
            "evidence_usage": "ì„ íƒëœ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ë°ì´í„°ë¥¼ êµ¬ì²´ì  ì‚¬ë¡€ì™€ ì„±ê³¼ ì§€í‘œë¡œ í™œìš©",
            "raw_data": state.extracted_data
        }


async def data_integrator_agent(state: PortfolioState) -> PortfolioState:
    """GPT ê¸°ë°˜ ì™„ì „ ë°ì´í„° í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    
    integrator = DataIntegratorAgent()
    return await integrator.integrate(state)