"""
Enhanced Router Agent - GPT ê¸°ë°˜ ì§ˆë¬¸ ë¶„ì„ ë° Extractor ì„ íƒ

ì—­í• :
1. GPTë¡œ ì§ˆë¬¸ ì˜ë„ ì™„ë²½ ë¶„ì„
2. í† ìŠ¤ ì±„ìš©ê³µê³  ê¸°ì¤€ìœ¼ë¡œ í•„ìš”í•œ Extractor ì„ íƒ  
3. ì„ íƒ ì´ìœ ì™€ í•¨ê»˜ state.selected_extractors ì„¤ì •
"""

import json
from typing import Dict, Any, List
from workflow.state import PortfolioState
from config.settings import Config
from utils.openai_client import get_openai_client

class EnhancedRouterAgent:
    """GPT ê¸°ë°˜ ì™„ì „ ìžìœ¨ ë¼ìš°í„° ì—ì´ì „íŠ¸"""
    
    async def analyze_and_route(self, state: PortfolioState) -> PortfolioState:
        """GPTë¡œ ì§ˆë¬¸ ë¶„ì„í•˜ê³  í•„ìš”í•œ Extractor ì„ íƒ"""
        
        print("\nðŸ§­ Enhanced Router Agent ì‹œìž‘")
        print(f"   ì§ˆë¬¸: {state.question}")
        print(f"   íšŒì‚¬: {state.company_context}")
        
        # GPTë¡œ ì§ˆë¬¸ ë¶„ì„í•˜ê³  Extractor ì„ íƒ
        routing_result = await self._gpt_analyze_and_select(state)
        
        # ê²°ê³¼ë¥¼ stateì— ì„¤ì •
        state.selected_extractors = routing_result.get("selected_extractors", [])
        state.intent = routing_result.get("intent", "general")
        state.intent_confidence = routing_result.get("confidence", 0.8)
        state.selection_reason = routing_result.get("reason", "")
        
        print(f"   GPT ì„ íƒ ê²°ê³¼: {state.selected_extractors}")
        print(f"   ì„ íƒ ì´ìœ : {state.selection_reason}")
        
        return state
    
    async def _gpt_analyze_and_select(self, state: PortfolioState) -> Dict[str, Any]:
        """GPTë¡œ ì§ˆë¬¸ ë¶„ì„ ë° Extractor ì„ íƒ"""
        
        try:
            client = get_openai_client()
            
            # í† ìŠ¤ ì±„ìš©ê³µê³  ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            toss_context = Config.get_company_context(state.company_context)
            
            prompt = f"""
{toss_context}

ìœ„ í† ìŠ¤ ML Engineer ì±„ìš© ì •ë³´ë¥¼ ëª¨ë‘ ìˆ™ì§€í•˜ê³ , ë‹¤ìŒ ë©´ì ‘ ì§ˆë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: "{state.question}"

í™©ì¤€í˜¸ì˜ ë°ì´í„° ì˜ì—­ 4ê°œ:
1. project: 4ê°œ í”„ë¡œì íŠ¸ (ë³´ë“œê²Œìž„ ì±—ë´‡=LLM/RAG, ë°ì´íŠ¸ ì¶”ì²œ=ì¶”ì²œì‹œìŠ¤í…œ, ì‹ ë¬¸ ì´íƒˆì˜ˆì¸¡=ML, ê°„í˜¸ì‚¬ ê¸‰ì—¬ì˜ˆì¸¡=íšŒê·€)
2. skill: ê¸°ìˆ ìŠ¤íƒ (LangChain, RAG, Vector DB, PyTorch, Spark, PostgreSQL, FastAPI, Next.js ë“±)
3. about_me: ê°œì¸ì  íŠ¹ì„± (ì„±ê²©, í˜‘ì—…, ì„±ìž¥, ë¦¬ë”ì‹­, ì±…ìž„ê°, ê°€ì¹˜ê´€)
4. cover_letter: ì§€ì› ë™ê¸° (í† ìŠ¤ ì§€ì› ì´ìœ , ëª©í‘œ, ê¸°ì—¬ ë°©ì•ˆ, í¬ë¶€)

í† ìŠ¤ê°€ ê°€ìž¥ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ê²ƒë“¤:
- AI ì˜ì—­ â­â­â­: LLM, RAG, ë©€í‹°ëª¨ë‹¬ (ìµœê³  ìš°ì„ ìˆœìœ„)
- ì¶”ì²œ ì‹œìŠ¤í…œ: ì‚¬ìš©ìž-ì½˜í…ì¸  ì—°ê²° ìµœì í™”
- ë¹„ì¦ˆë‹ˆìŠ¤ ìž„íŒ©íŠ¸: ë‹¨ìˆœ ëª¨ë¸ë§ì´ ì•„ë‹Œ ì‹¤ì œ ê²°ê³¼
- ë¹…ë°ì´í„° ì²˜ë¦¬: Hadoop, Spark, ëŒ€ìš©ëŸ‰ ë°ì´í„°
- ì£¼ë„ì  ê¸°ì—¬: ë³¸ì¸ì´ ì§ì ‘ ê¸°ì—¬í•œ êµ¬ì²´ì  ë¶€ë¶„

í† ìŠ¤ ì±„ìš©ë‹´ë‹¹ìž ê´€ì ì—ì„œ ì´ ì§ˆë¬¸ì— ê°€ìž¥ ì ì ˆí•˜ê²Œ ë‹µë³€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë°ì´í„° ì˜ì—­ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

ì„ íƒ ê¸°ì¤€:
- ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ íŒŒì•…
- í† ìŠ¤ ìš”êµ¬ì‚¬í•­ê³¼ì˜ ì—°ê´€ì„±
- í™©ì¤€í˜¸ì˜ ê°•ì  ì˜ì—­ ê³ ë ¤
- ë©´ì ‘ ë‹µë³€ì˜ ì™„ì„±ë„

ë‹¤ìŒ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "selected_extractors": ["ì˜ì—­1", "ì˜ì—­2", ...],
  "intent": "ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„",
  "confidence": 0.95,
  "reason": "í† ìŠ¤ ìš”êµ¬ì‚¬í•­ì„ ê³ ë ¤í•œ êµ¬ì²´ì  ì„ íƒ ì´ìœ "
}}

ì˜ˆì‹œ:
- "LLM ê²½í—˜ì´ ìžˆë‚˜ìš”?" â†’ ["project", "skill"] (ë³´ë“œê²Œìž„ ì±—ë´‡ í”„ë¡œì íŠ¸ + LLM ê¸°ìˆ ìŠ¤íƒ)
- "ì™œ í† ìŠ¤ì— ì§€ì›í–ˆë‚˜ìš”?" â†’ ["cover_letter"] (ì§€ì› ë™ê¸°ê°€ í•µì‹¬)
- "ì–´ë ¤ìš´ ìƒí™©ì„ ê·¹ë³µí•œ ê²½í—˜ì€?" â†’ ["project", "about_me"] (í”„ë¡œì íŠ¸ ê²½í—˜ + ê°œì¸ ì„±ìž¥)
"""

            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í† ìŠ¤ ML Engineer ì±„ìš©ë‹´ë‹¹ìžìž…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì •í™•ížˆ ë¶„ì„í•´ì„œ í•„ìš”í•œ ë°ì´í„° ì˜ì—­ì„ ì„ íƒí•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.3,
                max_tokens=400
            )
            
            gpt_response = response.choices[0].message.content.strip()
            print(f"   GPT ì‘ë‹µ: {gpt_response}")
            
            # JSON íŒŒì‹±
            try:
                result = json.loads(gpt_response)
                
                # ìœ íš¨í•œ extractorë§Œ í•„í„°ë§
                valid_extractors = ["project", "skill", "about_me", "cover_letter"]
                selected = result.get("selected_extractors", [])
                filtered_selected = [ext for ext in selected if ext in valid_extractors]
                
                return {
                    "selected_extractors": filtered_selected,
                    "intent": result.get("intent", "general"),
                    "confidence": result.get("confidence", 0.8),
                    "reason": result.get("reason", "GPT ë¶„ì„ ê²°ê³¼")
                }
                
            except json.JSONDecodeError:
                print(f"   âŒ GPT JSON íŒŒì‹± ì‹¤íŒ¨: {gpt_response}")
                # íŒŒì‹± ì‹¤íŒ¨ì‹œ ë³´ìˆ˜ì  ê¸°ë³¸ê°’
                return {
                    "selected_extractors": ["project", "skill"],
                    "intent": "general",
                    "confidence": 0.5,
                    "reason": "JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ì„ íƒ"
                }
            
        except Exception as e:
            print(f"   âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            # GPT í˜¸ì¶œ ì‹¤íŒ¨ì‹œ ë³´ìˆ˜ì  ê¸°ë³¸ê°’
            return {
                "selected_extractors": ["project", "skill"],
                "intent": "general", 
                "confidence": 0.3,
                "reason": f"GPT í˜¸ì¶œ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ì„ íƒ: {str(e)}"
            }


async def enhanced_router_agent(state: PortfolioState) -> PortfolioState:
    """Enhanced Router Agent ì‹¤í–‰ í•¨ìˆ˜"""
    router = EnhancedRouterAgent()
    return await router.analyze_and_route(state)