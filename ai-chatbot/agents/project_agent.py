"""
Project Agent - í”„ë¡œì íŠ¸ ìƒì„¸ ì„¤ëª… ì „ë¬¸

ì—­í• :
1. 4ê°œ í”„ë¡œì íŠ¸ ì¤‘ ì§ˆë¬¸ê³¼ ê°€ìž¥ ê´€ë ¨ìžˆëŠ” í”„ë¡œì íŠ¸ ì„ íƒ
2. MD íŒŒì¼ ê¸°ë°˜ êµ¬ì²´ì  ë¬¸ì œ í•´ê²° ê³¼ì • ì„¤ëª…
3. íšŒì‚¬ ìš”êµ¬ì‚¬í•­ê³¼ ë§¤ì¹­í•˜ì—¬ ë‹µë³€ ìƒì„±

í”„ë¡œì íŠ¸ ì¢…ë¥˜:
- ai-chatbot-portfolio: LangGraph ë©€í‹° ì—ì´ì „íŠ¸ (ì¸í„°ëž™í‹°ë¸Œ í¬íŠ¸í´ë¦¬ì˜¤)
- date-recommendation: LLM+ì¶”ì²œì‹œìŠ¤í…œ (ëŒ€í™”í˜• AI ì±—ë´‡)
- boardgame-chatbot: RAG+íŒŒì¸íŠœë‹ (ì‹¤ì‹œê°„ ëŒ€í™”í˜• ì±—ë´‡)
- newspaper-churn: ë¨¸ì‹ ëŸ¬ë‹ ì´íƒˆì˜ˆì¸¡ (Streamlit ëŒ€ì‹œë³´ë“œ)
- nurse-salary: ë¨¸ì‹ ëŸ¬ë‹ í‡´ì‚¬ì˜ˆì¸¡ (ë¶„ì„ ë¦¬í¬íŠ¸)
"""

import json
import os
from typing import Dict, Any, List
from workflow.state import ChatState
from config.settings import Config
from utils.openai_client import get_openai_client
from utils.json_parser import parse_json_response

class ProjectAgent:
    """í”„ë¡œì íŠ¸ ìƒì„¸ ì„¤ëª… ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.project_metadata = {
            "date-recommendation": {
                "category": "LLM+ì¶”ì²œì‹œìŠ¤í…œ",
                "type": "í’€ìŠ¤íƒ ì„œë¹„ìŠ¤",
                "tech_domain": ["LLM", "RAG", "ì¶”ì²œì‹œìŠ¤í…œ", "ë²¡í„°DB", "ë¹…ë°ì´í„°"],
                "interface": "ëŒ€í™”í˜• AI ì±—ë´‡",
                "key_feature": "151ê°œ ì¹´í…Œê³ ë¦¬ â†’ ê±°ë¦¬ â†’ ë²¡í„° 3ë‹¨ê³„ í•„í„°ë§",
                "performance": "33ì´ˆâ†’3.4ì´ˆ (90% ê°œì„ )",
                "scale": "89,321ê°œ ìž¥ì†Œ DB",
                "title": "ë°ì´íŠ¸ ì½”ìŠ¤ AI ì¶”ì²œ ì‹œìŠ¤í…œ",
                "url": "/date-recommendation"
            },
            "boardgame-chatbot": {
                "category": "RAG+íŒŒì¸íŠœë‹",
                "type": "AI ì±—ë´‡ ì„œë¹„ìŠ¤",
                "tech_domain": ["RAG", "íŒŒì¸íŠœë‹", "ë²¡í„°DB", "NLP"],
                "interface": "ì‹¤ì‹œê°„ ëŒ€í™”í˜• ì±—ë´‡",
                "key_feature": "217ê°œ ê²Œìž„ë³„ ë…ë¦½ FAISS DB + EXAONE íŒŒì¸íŠœë‹",
                "performance": "QA ìžë™ìˆ˜ì§‘ ì‹œìŠ¤í…œ",
                "scale": "217ê°œ ê²Œìž„ ì»¤ë²„",
                "title": "ë³´ë“œê²Œìž„ RAG ì±—ë´‡",
                "url": "/boardgame-chatbot"
            },
            "newspaper-churn": {
                "category": "ë¨¸ì‹ ëŸ¬ë‹",
                "type": "ì˜ˆì¸¡ ëª¨ë¸",
                "tech_domain": ["ML", "ë¶„ë¥˜", "ë¶ˆê· í˜•ì²˜ë¦¬"],
                "interface": "Streamlit ëŒ€ì‹œë³´ë“œ",
                "key_feature": "SMOTEë¡œ 4.7:1â†’1:1 í´ëž˜ìŠ¤ ê· í˜•",
                "performance": "87% F1-Score, 0.94 ROC AUC",
                "scale": "15,855ëª… ë°ì´í„°",
                "title": "ì‹ ë¬¸ ì´íƒˆ ì˜ˆì¸¡ ML",
                "url": "/newspaper-churn"
            },
            "nurse-salary": {
                "category": "ë¨¸ì‹ ëŸ¬ë‹",
                "type": "ì˜ˆì¸¡ ëª¨ë¸",
                "tech_domain": ["ML", "íšŒê·€", "ë„ë©”ì¸ì§€ì‹"],
                "interface": "ë¶„ì„ ë¦¬í¬íŠ¸",
                "key_feature": "55ì„¸ ì´ìƒ ì€í‡´ìž ë¶„ë¦¬ ë„ë©”ì¸ ì§€ì‹",
                "performance": "93% ì •í™•ë„, 0.76 F1-Score",
                "scale": "794ëª… ê°„í˜¸ì‚¬ ë°ì´í„°",
                "title": "ê°„í˜¸ì‚¬ í‡´ì‚¬ ì˜ˆì¸¡ ML",
                "url": "/nurse-salary"
            },
            "ai-chatbot-portfolio": {
                "category": "LangGraph ë©€í‹° ì—ì´ì „íŠ¸",
                "type": "í’€ìŠ¤íƒ ì„œë¹„ìŠ¤",
                "tech_domain": ["LangGraph", "Agent", "FastAPI", "Next.js"],
                "interface": "ì¸í„°ëž™í‹°ë¸Œ í¬íŠ¸í´ë¦¬ì˜¤",
                "key_feature": "ì§ˆë¬¸ ìœ í˜•ë³„ ì „ë¬¸ ì—ì´ì „íŠ¸ ì¡°ê±´ë¶€ ë¼ìš°íŒ…",
                "performance": "ì‹¤ì‹œê°„ ëŒ€í™”í˜• AI ê²½í—˜",
                "scale": "ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œìŠ¤í…œ",
                "title": "AI ì±—ë´‡ í¬íŠ¸í´ë¦¬ì˜¤",
                "url": "/ai-chatbot-portfolio"
            }
        }
    
    async def process(self, state: ChatState) -> ChatState:
        """í”„ë¡œì íŠ¸ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬"""
        
        print(f"\nðŸ“¦ Project Agent ì‹œìž‘")
        print(f"   ì§ˆë¬¸: {state.question}")
        print(f"   íšŒì‚¬: {state.company_context}")
        
        try:
            # 1. GPTë¡œ ê´€ë ¨ í”„ë¡œì íŠ¸ ì„ íƒ
            selected_projects = await self._select_projects(state)
            print(f"   ì„ íƒëœ í”„ë¡œì íŠ¸: {selected_projects}")
            
            # 2. ì„ íƒëœ í”„ë¡œì íŠ¸ MD íŒŒì¼ ì½ê¸°
            md_contents = await self._read_project_files(selected_projects)
            
            # 3. GPTë¡œ ë‹µë³€ ìƒì„±
            answer = await self._generate_answer(state, selected_projects, md_contents)
            
            # 4. ë‹µë³€ì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ í”„ë¡œì íŠ¸ ì¶”ì¶œ í›„ ë§í¬ ìƒì„±
            clean_answer, links = self._generate_links_from_answer(answer)
            
            # 5. State ì—…ë°ì´íŠ¸ (ì •ì œëœ ë‹µë³€ ì‚¬ìš©)
            state.response = clean_answer
            state.recommended_links = links
            state.response_quality_score = 0.9
            
            print(f"   âœ… Project Agent ì™„ë£Œ")
            print(f"   ðŸ“ ë‹µë³€ ê¸¸ì´: {len(answer)}ìž")
            print(f"   ðŸ”— ì¶”ì²œ ë§í¬: {len(links)}ê°œ")
            
        except Exception as e:
            print(f"   âŒ Project Agent ì˜¤ë¥˜: {str(e)}")
            # í´ë°± ì²˜ë¦¬
            state.response = "ì£„ì†¡í•©ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            state.recommended_links = {}
            state.response_quality_score = 0.3
        
        return state
    
    async def _select_projects(self, state: ChatState) -> List[str]:
        """GPTë¡œ ì§ˆë¬¸ê³¼ ê´€ë ¨ìžˆëŠ” í”„ë¡œì íŠ¸ ì„ íƒ (ëŒ€í™” ë§¥ë½ ê³ ë ¤)"""
        
        try:
            client = get_openai_client()
            company_context = Config.get_company_context(state.company_context)
            
            # 4ê°œ í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° í¬ë§·íŒ…
            projects_info = self._format_projects_metadata()
            
            # ëŒ€í™” ížˆìŠ¤í† ë¦¬ í¬ë§·íŒ… (ìµœê·¼ 4ê°œ)
            history_text = ""
            if state.conversation_history:
                recent_history = state.conversation_history[-4:]
                for msg in recent_history:
                    role = "ì§ˆë¬¸" if msg['role'] == 'user' else "ë‹µë³€"
                    history_text += f"{role}: {msg['content'][:200]}...\n\n"
            
            prompt = f"""
{company_context}

=== ì´ì „ ëŒ€í™” ë§¥ë½ ===
{history_text if history_text else "ì²« ë²ˆì§¸ ì§ˆë¬¸ìž…ë‹ˆë‹¤."}

=== í˜„ìž¬ ì§ˆë¬¸ ===
"{state.question}"

í™©ì¤€í˜¸ì˜ 4ê°œ í”„ë¡œì íŠ¸ ì •ë³´:
{projects_info}

ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™:
1. ì§ˆë¬¸ì—ì„œ íŠ¹ì • í”„ë¡œì íŠ¸ë¥¼ ì§ì ‘ ì–¸ê¸‰í–ˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ í”„ë¡œì íŠ¸ë§Œì„ ì„ íƒí•˜ì„¸ìš”.
2. ì´ì „ ëŒ€í™”ì—ì„œ íŠ¹ì • í”„ë¡œì íŠ¸ë¥¼ ë…¼ì˜ ì¤‘ì´ì—ˆê³ , í˜„ìž¬ ì§ˆë¬¸ì´ "ê·¸ í”„ë¡œì íŠ¸ì—ì„œ", "ê±°ê¸°ì„œ", "ê·¸ëŸ¼" ë“±ìœ¼ë¡œ ì´ì–´ì§„ë‹¤ë©´ ê°™ì€ í”„ë¡œì íŠ¸ë§Œì„ ì„ íƒí•˜ì„¸ìš”.
3. ì§ˆë¬¸ì´ íŠ¹ì • ê¸°ìˆ (íŒŒì¸íŠœë‹, SMOTE ë“±)ì„ ì–¸ê¸‰í•˜ê³  ì´ì „ì— í”„ë¡œì íŠ¸ë¥¼ ë…¼ì˜í–ˆë‹¤ë©´, ê·¸ í”„ë¡œì íŠ¸ì˜ ë§¥ë½ì—ì„œ ë‹µë³€í•˜ì„¸ìš”.

í”„ë¡œì íŠ¸ëª… ë§¤í•‘:
- "í¬íŠ¸í´ë¦¬ì˜¤" ì–¸ê¸‰ â†’ ai-chatbot-portfolio
- "ë³´ë“œê²Œìž„" ì–¸ê¸‰ â†’ boardgame-chatbot
- "ë°ì´íŠ¸" ì–¸ê¸‰ â†’ date-recommendation  
- "ì‹ ë¬¸" ë˜ëŠ” "ì´íƒˆ" ì–¸ê¸‰ â†’ newspaper-churn
- "ê°„í˜¸ì‚¬" ë˜ëŠ” "í‡´ì‚¬" ì–¸ê¸‰ â†’ nurse-salary

ì´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ê°€ìž¥ ì í•©í•œ í”„ë¡œì íŠ¸ë¥¼ ì˜ë„ì˜ ê°œìˆ˜ì— ë§žë„ë¡(1~5ê°œ ì‚¬ì´) ì„ íƒí•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
    "selected_projects": ["í”„ë¡œì íŠ¸ëª…1", "í”„ë¡œì íŠ¸ëª…2", "í”„ë¡œì íŠ¸ëª…3", "í”„ë¡œì íŠ¸ëª…4"],
    "reasoning": "ì„ íƒí•œ ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…"
}}
ê°¯ìˆ˜ì— ë§žë„ë¡ í”„ë¡œì íŠ¸ ëª…ì„ ì¨ì„œ ë³´ë‚´ì£¼ë©´ ë¨
"""

            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ìš© ë©´ì ‘ì—ì„œ ì§€ì›ìžì˜ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.3,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            print(f"   ðŸ¤– í”„ë¡œì íŠ¸ ì„ íƒ GPT ì‘ë‹µ: {result_text}")
            
            # JSON íŒŒì‹±
            result = parse_json_response(result_text)
            selected = result.get("selected_projects", [])
            
            # ìœ íš¨í•œ í”„ë¡œì íŠ¸ë§Œ í•„í„°ë§
            valid_projects = [p for p in selected if p in self.project_metadata.keys()]
            
            if not valid_projects:
                # ì„ íƒ ì‹¤íŒ¨ì‹œ ê°€ìž¥ ì™„ì„±ë„ ë†’ì€ date-recommendation ì„ íƒ
                valid_projects = ["date-recommendation"]
                print("   âš ï¸ í”„ë¡œì íŠ¸ ì„ íƒ ì‹¤íŒ¨, date-recommendationìœ¼ë¡œ í´ë°±")
            
            return valid_projects
            
        except Exception as e:
            print(f"   âŒ í”„ë¡œì íŠ¸ ì„ íƒ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ì‹œ ê¸°ë³¸ í”„ë¡œì íŠ¸ ì„ íƒ
            return ["date-recommendation"]
    
    def _format_projects_metadata(self) -> str:
        """4ê°œ í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ GPTê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        
        formatted = ""
        for project_key, metadata in self.project_metadata.items():
            formatted += f"""
=== {project_key} ===
ë¶„ë¥˜: {metadata['category']}
ìœ í˜•: {metadata['type']} ({metadata['interface']})
í•µì‹¬ ê¸°ìˆ : {', '.join(metadata['tech_domain'])}
í•µì‹¬ íŠ¹ì§•: {metadata['key_feature']}
ì„±ê³¼: {metadata['performance']}
ê·œëª¨: {metadata['scale']}
"""
        
        return formatted
    
    async def _read_project_files(self, selected_projects: List[str]) -> Dict[str, str]:
        """ì„ íƒëœ í”„ë¡œì íŠ¸ë“¤ì˜ MD íŒŒì¼ ì½ê¸°"""
        
        md_contents = {}
        
        for project in selected_projects:
            try:
                file_path = os.path.join(Config.PROJECT_DATA_PATH, f"{project}.md")
                
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        md_contents[project] = content
                        print(f"   ðŸ“„ {project}.md ì½ê¸° ì„±ê³µ ({len(content)}ìž)")
                else:
                    print(f"   âŒ {project}.md íŒŒì¼ ì—†ìŒ: {file_path}")
                    md_contents[project] = ""
                    
            except Exception as e:
                print(f"   âŒ {project}.md ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                md_contents[project] = ""
        
        return md_contents
    
    async def _generate_answer(self, state: ChatState, selected_projects: List[str], md_contents: Dict[str, str]) -> str:
        """GPTë¡œ í”„ë¡œì íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„± (ëŒ€í™” ë§¥ë½ ê³ ë ¤)"""
        
        try:
            client = get_openai_client()
            company_context = Config.get_company_context(state.company_context)
            
            # MD íŒŒì¼ ë‚´ìš© í¬ë§·íŒ…
            projects_content = ""
            for project, content in md_contents.items():
                if content:
                    projects_content += f"\n=== {project} í”„ë¡œì íŠ¸ ===\n{content}\n"
            
            # ëŒ€í™” ížˆìŠ¤í† ë¦¬ í¬ë§·íŒ… (ìµœê·¼ 2ê°œ)
            history_context = ""
            if state.conversation_history:
                recent = state.conversation_history[-2:]
                for msg in recent:
                    role = "ì§ˆë¬¸" if msg['role'] == 'user' else "ë‹µë³€"
                    history_context += f"{role}: {msg['content'][:300]}...\n\n"
            
            prompt = f"""
{company_context}

=== ì´ì „ ëŒ€í™” ===
{history_context if history_context else "ì²« ë²ˆì§¸ ì§ˆë¬¸ìž…ë‹ˆë‹¤."}

=== í˜„ìž¬ ì§ˆë¬¸ ===
"{state.question}"

í™©ì¤€í˜¸ì˜ ì„ íƒëœ í”„ë¡œì íŠ¸ ì „ì²´ ë‚´ìš©:
{projects_content}

ì¤‘ìš”: ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ì´ì–´ì„œ ë‹µë³€í•˜ì„¸ìš”. ê°™ì€ í”„ë¡œì íŠ¸ë¥¼ ê³„ì† ë…¼ì˜ ì¤‘ì´ë¼ë©´ ì¼ê´€ì„± ìžˆê²Œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ ìƒì„± ìš”êµ¬ì‚¬í•­:
1. í”„ë¡œì íŠ¸ ìœ í˜•ê³¼ íŠ¹ì„± ëª…ì‹œ (LLM/ì¶”ì²œ/ML, ëŒ€í™”í˜•/ì‹¤ì‹œê°„ ë“±)
2. "## êµ¬í˜„ ì¤‘ ì–´ë ¤ì›€ê³¼ ë¬¸ì œ í•´ê²°" ì„¹ì…˜ì„ ìµœìš°ì„ ìœ¼ë¡œ í™œìš©
3. ë¬¸ì œ ì •ì˜ â†’ ì›ì¸ ë¶„ì„ â†’ í•´ê²° ë°©ë²• â†’ ê²°ê³¼ ìˆœì„œë¡œ ì„¤ëª…
4. êµ¬ì²´ì  êµ¬í˜„ ë°©ë²• (HOW) ê°•ì¡° (ë²¡í„° í•„í„°ë§, ì¸ë©”ëª¨ë¦¬ ì²˜ë¦¬, SMOTE ë“±)
5. íšŒì‚¬ ìš”êµ¬ì‚¬í•­ê³¼ ì—°ê²°í•˜ì—¬ ì–´í•„
6. 150-200ë‹¨ì–´
7. ë‹µë³€ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ "ê´€ë ¨ í”„ë¡œì íŠ¸: [í”„ë¡œì íŠ¸ëª…]" í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”

íŠ¹ížˆ ë°ì´íŠ¸ ì¶”ì²œ í”„ë¡œì íŠ¸ì˜ ê²½ìš° "151ê°œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ â†’ ê±°ë¦¬ í•„í„°ë§ â†’ ë²¡í„° ê²€ìƒ‰" 3ë‹¨ê³„ ì „ëžµì„ ê°•ì¡°í•˜ì„¸ìš”.

ë©´ì ‘ê´€ì—ê²Œ í•˜ëŠ” ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë‹µë³€í•˜ë˜, ê¸°ìˆ ì  ê¹Šì´ì™€ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ì¤‘ì ì ìœ¼ë¡œ ì–´í•„í•˜ì„¸ìš”.

ì¤‘ìš”: ë‹µë³€ ë§ˆì§€ë§‰ ì¤„ì— ì •í™•ížˆ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”:
ê´€ë ¨ í”„ë¡œì íŠ¸: [date-recommendation]
ë˜ëŠ” 
ê´€ë ¨ í”„ë¡œì íŠ¸: [date-recommendation, boardgame-chatbot]

ëŒ€ê´„í˜¸ì™€ í”„ë¡œì íŠ¸ëª…ì„ ì •í™•ížˆ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""

            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ìš© ë©´ì ‘ì—ì„œ ì§€ì›ìžì˜ í”„ë¡œì íŠ¸ ê²½í—˜ì„ íš¨ê³¼ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.7,
                max_tokens=1500
            )
            
            answer = response.choices[0].message.content.strip()
            print(f"   ðŸ¤– ë‹µë³€ ìƒì„±: {answer[:100]}...")
            
            return answer
            
        except Exception as e:
            print(f"   âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{state.question}' ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_links_from_answer(self, answer: str) -> tuple[str, Dict[str, str]]:
        """ë‹µë³€ì—ì„œ 'ê´€ë ¨ í”„ë¡œì íŠ¸: [...]' ì¶”ì¶œí•´ì„œ í•´ë‹¹ í”„ë¡œì íŠ¸ë§Œ ë§í¬ ìƒì„±"""
        
        import re
        
        # "ê´€ë ¨ í”„ë¡œì íŠ¸: [í”„ë¡œì íŠ¸ëª…1, í”„ë¡œì íŠ¸ëª…2]" íŒ¨í„´ ì°¾ê¸°
        pattern = r"ê´€ë ¨ í”„ë¡œì íŠ¸: \[([^\]]+)\]"
        match = re.search(pattern, answer)
        
        links = {}
        clean_answer = answer
        
        if match:
            # í”„ë¡œì íŠ¸ëª…ë“¤ ì¶”ì¶œ
            projects_text = match.group(1)
            used_projects = [p.strip() for p in projects_text.split(',')]
            
            # í•´ë‹¹ ë¶€ë¶„ ë‹µë³€ì—ì„œ ì œê±° (ì‚¬ìš©ìžì—ê²ŒëŠ” ë³´ì´ì§€ ì•Šê²Œ)
            clean_answer = re.sub(pattern, '', answer).strip()
            
            # â­ ì´ëª¨ì§€ë„ ì œê±° (GPTê°€ ìž˜ëª» í¬í•¨ì‹œí‚¬ ìˆ˜ ìžˆìŒ)
            clean_answer = clean_answer.replace('â­', '').strip()
            
            # ì¶”ì¶œëœ í”„ë¡œì íŠ¸ë“¤ë§Œ ë§í¬ ìƒì„±
            for project in used_projects:
                if project in self.project_metadata:
                    metadata = self.project_metadata[project]
                    links[metadata["title"]] = metadata["url"]
                    print(f"   ðŸ”— ë§í¬ ìƒì„±: {project} -> {metadata['title']}")
            
            print(f"   ðŸ“Š ë‹µë³€ì—ì„œ ì¶”ì¶œëœ í”„ë¡œì íŠ¸: {used_projects}")
            
        else:
            # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ í´ë°± - ë¹ˆ ë§í¬
            # â­ ì´ëª¨ì§€ëŠ” ì œê±°
            clean_answer = clean_answer.replace('â­', '').strip()
            print("   âš ï¸ 'ê´€ë ¨ í”„ë¡œì íŠ¸: [...]' íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        return clean_answer, links

    def _generate_links(self, selected_projects: List[str]) -> Dict[str, str]:
        """ê¸°ì¡´ ë©”ì„œë“œ (í˜¸í™˜ì„± ìœ ì§€)"""
        
        links = {}
        
        for project in selected_projects:
            if project in self.project_metadata:
                metadata = self.project_metadata[project]
                links[metadata["title"]] = metadata["url"]
        
        return links

async def project_agent(state: ChatState) -> ChatState:
    """Project Agent ì‹¤í–‰ í•¨ìˆ˜"""
    agent = ProjectAgent()
    return await agent.process(state)