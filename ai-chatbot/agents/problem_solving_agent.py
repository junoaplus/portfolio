"""
Problem Solving Agent - ë¬¸ì œ í•´ê²° ê³¼ì • ì „ë¬¸

ì—­í• :
1. "êµ¬í˜„ ì¤‘ ì–´ë ¤ì›€ê³¼ ë¬¸ì œ í•´ê²°" ì„¹ì…˜ ê¸°ë°˜ ë‹µë³€
2. ë¬¸ì œ ì •ì˜ â†’ í•´ê²° ê³¼ì • â†’ ì„±ê³¼ êµ¬ì²´ì  ì„¤ëª…
3. ì„±ëŠ¥ ìµœì í™” ìˆ˜ì¹˜ì™€ ê¸°ìˆ ì  ê¹Šì´ ê°•ì¡°

ì²˜ë¦¬í•˜ëŠ” ì§ˆë¬¸ ì˜ˆì‹œ:
- "33ì´ˆë¥¼ 3.4ì´ˆë¡œ ì¤„ì¸ ë°©ë²•ì´ ë­”ê°€ìš”?"
- "í´ëž˜ìŠ¤ ë¶ˆê· í˜•ì€ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?"
- "ê°€ìž¥ ì–´ë ¤ì› ë˜ ê¸°ìˆ ì  ì±Œë¦°ì§€ëŠ”?"
- "ì„±ëŠ¥ ìµœì í™” ê²½í—˜ì´ ìžˆë‚˜ìš”?"
"""

import json
import os
import re
from typing import Dict, Any, List
from workflow.state import ChatState
from config.settings import Config
from utils.openai_client import get_openai_client
from utils.json_parser import parse_json_response

class ProblemSolvingAgent:
    """ë¬¸ì œ í•´ê²° ê³¼ì • ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        # í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ë§Œ (í‚¤ì›Œë“œ ë§¤í•‘ ì—†ìŒ)
        self.projects = ["ai-chatbot-portfolio", "date-recommendation", "boardgame-chatbot", "newspaper-churn", "nurse-salary"]
        self.project_titles = {
            "ai-chatbot-portfolio": "AI ì±—ë´‡ í¬íŠ¸í´ë¦¬ì˜¤",
            "date-recommendation": "ë°ì´íŠ¸ ì½”ìŠ¤ AI ì¶”ì²œ ì‹œìŠ¤í…œ",
            "boardgame-chatbot": "ë³´ë“œê²Œìž„ RAG ì±—ë´‡",
            "newspaper-churn": "ì‹ ë¬¸ ì´íƒˆ ì˜ˆì¸¡ ML", 
            "nurse-salary": "ê°„í˜¸ì‚¬ í‡´ì‚¬ ì˜ˆì¸¡ ML"
        }
    
    async def process(self, state: ChatState) -> ChatState:
        """ë¬¸ì œ í•´ê²° ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬"""
        
        print(f"\nðŸ”§ Problem Solving Agent ì‹œìž‘")
        print(f"   ì§ˆë¬¸: {state.question}")
        print(f"   íšŒì‚¬: {state.company_context}")
        
        try:
            # 1ë‹¨ê³„: GPTë¡œ ë¬¸ì œí•´ê²° ì§ˆë¬¸ ë¶„ì„
            analysis = await self._analyze_problem_question(state.question)
            print(f"   ì§ˆë¬¸ ë¶„ì„: {analysis.get('question_type', 'N/A')}")
            
            # 2ë‹¨ê³„: ëª¨ë“  í”„ë¡œì íŠ¸ MD íŒŒì¼ì˜ ë¬¸ì œí•´ê²° ì„¹ì…˜ ì½ê¸°
            all_problem_sections = await self._read_all_problem_sections()
            
            # 3ë‹¨ê³„: GPTë¡œ ì§ˆë¬¸ê³¼ ê°€ìž¥ ê´€ë ¨ìžˆëŠ” í”„ë¡œì íŠ¸ 1-2ê°œ ì„ íƒ
            selected_projects = await self._select_relevant_problems(state.question, all_problem_sections)
            print(f"   ì„ íƒëœ í”„ë¡œì íŠ¸: {selected_projects}")
            
            # 4ë‹¨ê³„: ì„ íƒëœ í”„ë¡œì íŠ¸ì˜ ë¬¸ì œí•´ê²° ë‚´ìš©ë§Œ ì¶”ì¶œ
            relevant_sections = {p: all_problem_sections[p] for p in selected_projects if p in all_problem_sections}
            
            # 5ë‹¨ê³„: GPTë¡œ ë¬¸ì œí•´ê²° ë‹µë³€ ìƒì„±
            answer = await self._generate_problem_answer(state, relevant_sections)
            
            # 6ë‹¨ê³„: ì„ íƒëœ í”„ë¡œì íŠ¸ ë§í¬ ìƒì„±
            project_links = self._generate_project_links(selected_projects)
            
            # 7ë‹¨ê³„: State ì—…ë°ì´íŠ¸
            state.response = answer
            state.recommended_links = project_links
            state.response_quality_score = 0.9
            
            print(f"   âœ… Problem Solving Agent ì™„ë£Œ")
            print(f"   ðŸ“ ë‹µë³€ ê¸¸ì´: {len(answer)}ìž")
            print(f"   ðŸ”— ì¶”ì²œ ë§í¬: {len(project_links)}ê°œ")
            
        except Exception as e:
            print(f"   âŒ Problem Solving Agent ì˜¤ë¥˜: {str(e)}")
            # í´ë°± ì²˜ë¦¬
            state.response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì œ í•´ê²° ì‚¬ë¡€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            state.recommended_links = {}
            state.response_quality_score = 0.3
        
        return state
    
    async def _analyze_problem_question(self, question: str) -> Dict[str, Any]:
        """GPTë¡œ ë¬¸ì œí•´ê²° ì§ˆë¬¸ ë¶„ì„"""
        
        try:
            client = get_openai_client()
            
            prompt = f"""
ë‹¤ìŒì€ ë¬¸ì œ í•´ê²° ê´€ë ¨ ë©´ì ‘ ì§ˆë¬¸ìž…ë‹ˆë‹¤.

ì§ˆë¬¸: "{question}"

ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì„ ë¶„ì„í•˜ì„¸ìš”:
- ì–´ë–¤ ì¢…ë¥˜ì˜ ë¬¸ì œ í•´ê²°ì„ ë¬»ê³  ìžˆëŠ”ê°€?
- ê¸°ìˆ ì  ê¹Šì´ëŠ” ì–´ëŠ ì •ë„ë¥¼ ì›í•˜ëŠ”ê°€?
- êµ¬ì²´ì  ì‚¬ë¡€ë¥¼ ì›í•˜ëŠ”ê°€?

JSON ì‘ë‹µ:
{{
    "question_type": "ë¬¸ì œí•´ê²° ìœ í˜•",
    "technical_depth": "ì›í•˜ëŠ” ê¸°ìˆ ì  ê¹Šì´", 
    "specific_case": "êµ¬ì²´ì  ì‚¬ë¡€ í•„ìš” ì—¬ë¶€"
}}
"""
            
            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì œ í•´ê²° ì§ˆë¬¸ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.3,
                max_tokens=400
            )
            
            result_text = response.choices[0].message.content.strip()
            print(f"   ðŸ¤– ì§ˆë¬¸ ë¶„ì„ GPT ì‘ë‹µ: {result_text}")
            
            result = parse_json_response(result_text)
            return result
            
        except Exception as e:
            print(f"   âŒ ì§ˆë¬¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {"question_type": "ì¼ë°˜ ë¬¸ì œí•´ê²°", "technical_depth": "ì¤‘ê°„", "specific_case": "í•„ìš”"}
    
    async def _read_all_problem_sections(self) -> Dict[str, str]:
        """ëª¨ë“  í”„ë¡œì íŠ¸ MD íŒŒì¼ì˜ ë¬¸ì œí•´ê²° ì„¹ì…˜ ì½ê¸°"""
        
        all_sections = {}
        
        for project in self.projects:
            try:
                file_path = os.path.join(Config.PROJECT_DATA_PATH, f"{project}.md")
                
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ì •ê·œì‹ìœ¼ë¡œ "## êµ¬í˜„ ì¤‘ ì–´ë ¤ì›€ê³¼ ë¬¸ì œ í•´ê²°" ì„¹ì…˜ ì¶”ì¶œ
                    pattern = r'## êµ¬í˜„ ì¤‘ ì–´ë ¤ì›€ê³¼ ë¬¸ì œ í•´ê²°(.*?)(?=\n## |\n# |$)'
                    match = re.search(pattern, content, re.DOTALL)
                    
                    if match:
                        all_sections[project] = match.group(1).strip()
                        print(f"   ðŸ“„ {project} ë¬¸ì œí•´ê²° ì„¹ì…˜ ì¶”ì¶œ ì„±ê³µ ({len(match.group(1))}ìž)")
                    else:
                        all_sections[project] = ""
                        print(f"   âš ï¸ {project} ë¬¸ì œí•´ê²° ì„¹ì…˜ ì—†ìŒ")
                else:
                    print(f"   âŒ {project}.md íŒŒì¼ ì—†ìŒ")
                    all_sections[project] = ""
                    
            except Exception as e:
                print(f"   âŒ {project} íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                all_sections[project] = ""
        
        return all_sections
    
    async def _select_relevant_problems(self, question: str, all_sections: Dict[str, str]) -> List[str]:
        """GPTë¡œ ì§ˆë¬¸ê³¼ ê°€ìž¥ ê´€ë ¨ìžˆëŠ” í”„ë¡œì íŠ¸ 1-2ê°œ ì„ íƒ"""
        
        try:
            client = get_openai_client()
            
            # ëª¨ë“  í”„ë¡œì íŠ¸ì˜ ë¬¸ì œí•´ê²° ë‚´ìš©ì„ GPTì—ê²Œ ì „ì²´ ì œê³µ
            sections_content = ""
            for project, content in all_sections.items():
                if content:
                    # ì „ì²´ ë‚´ìš© ì œê³µ (í’ˆì§ˆ ë†’ì€ ë‹µë³€ì„ ìœ„í•´)
                    sections_content += f"\n=== {project} ===\n{content}\n"
            
            prompt = f"""
ë©´ì ‘ ì§ˆë¬¸: "{question}"

4ê°œ í”„ë¡œì íŠ¸ì˜ ë¬¸ì œ í•´ê²° ì‚¬ë¡€:
{sections_content}

ì´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ê°€ìž¥ ì í•©í•œ í”„ë¡œì íŠ¸ë¥¼ 1-2ê°œ ì„ íƒí•˜ì„¸ìš”.
ì§ˆë¬¸ê³¼ ê°€ìž¥ ìœ ì‚¬í•œ ë¬¸ì œ í•´ê²° ê²½í—˜ì„ ê°€ì§„ í”„ë¡œì íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.

JSON ì‘ë‹µ:
{{
    "selected_projects": ["í”„ë¡œì íŠ¸ëª…1", "í”„ë¡œì íŠ¸ëª…2"],
    "reasoning": "ì„ íƒ ì´ìœ "
}}
"""
            
            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì œ í•´ê²° ì‚¬ë¡€ ë§¤ì¹­ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.3,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            print(f"   ðŸ¤– í”„ë¡œì íŠ¸ ì„ íƒ GPT ì‘ë‹µ: {result_text}")
            
            result = parse_json_response(result_text)
            selected = result.get("selected_projects", [])
            
            # ìœ íš¨í•œ í”„ë¡œì íŠ¸ë§Œ í•„í„°ë§
            valid_projects = [p for p in selected if p in self.projects]
            
            if not valid_projects:
                # ì„ íƒ ì‹¤íŒ¨ì‹œ ì„±ëŠ¥ ìµœì í™”ê°€ ë‹ë³´ì´ëŠ” date-recommendation ì„ íƒ
                valid_projects = ["date-recommendation"]
                print("   âš ï¸ í”„ë¡œì íŠ¸ ì„ íƒ ì‹¤íŒ¨, date-recommendationìœ¼ë¡œ í´ë°±")
            
            return valid_projects
            
        except Exception as e:
            print(f"   âŒ í”„ë¡œì íŠ¸ ì„ íƒ ì˜¤ë¥˜: {str(e)}")
            return ["date-recommendation"]
    
    async def _generate_problem_answer(self, state: ChatState, relevant_sections: Dict[str, str]) -> str:
        """GPTë¡œ ë¬¸ì œí•´ê²° ë‹µë³€ ìƒì„±"""
        
        try:
            client = get_openai_client()
            company_context = Config.get_company_context(state.company_context)
            
            # ì„ íƒëœ í”„ë¡œì íŠ¸ì˜ ë¬¸ì œí•´ê²° ì„¹ì…˜ ì „ì²´ ì œê³µ
            problem_content = ""
            for project, content in relevant_sections.items():
                if content:
                    problem_content += f"\n=== {project} í”„ë¡œì íŠ¸ ë¬¸ì œí•´ê²° ===\n{content}\n"
            
            prompt = f"""
{company_context}

ë©´ì ‘ ì§ˆë¬¸: "{state.question}"

ê´€ë ¨ ë¬¸ì œ í•´ê²° ì‚¬ë¡€:
{problem_content}

ðŸš¨ ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™:
1. ì œê³µëœ í”„ë¡œì íŠ¸ ë°ì´í„°ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ì—†ëŠ” ê²½í—˜ì´ë‚˜ í”„ë¡œì íŠ¸ë¥¼ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
3. ì œê³µëœ í”„ë¡œì íŠ¸ ë‚´ìš©ì— ì—†ëŠ” ê¸°ìˆ ì´ë‚˜ êµ¬í˜„ ë°©ë²• ì°½ìž‘ ê¸ˆì§€

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. êµ¬ì²´ì  ë¬¸ì œ ìƒí™© ë¨¼ì € ì„¤ëª… (ì‹¤ì œ í”„ë¡œì íŠ¸ ê¸°ë°˜ë§Œ)
2. ë¬¸ì œ ì›ì¸ ë¶„ì„ê³¼ ì ‘ê·¼ ë°©ë²•
3. ì‹¤ì œ í•´ê²° ë°©ë²•ê³¼ êµ¬í˜„ ê³¼ì • (HOW ì¤‘ì‹¬)
4. íšŒì‚¬ ìš”êµ¬ì‚¬í•­ê³¼ ë¬¸ì œí•´ê²° ëŠ¥ë ¥ ì—°ê²°
5. 150-200ë‹¨ì–´

ë¬¸ì œ ì •ì˜ â†’ í•´ê²° ê³¼ì • â†’ ì„±ê³¼ ìˆœì„œë¡œ ë©´ì ‘ê´€ì—ê²Œ í•˜ëŠ” ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
ì œê³µëœ ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ê³ , ì°½ìž‘í•˜ì§€ ë§ˆì„¸ìš”.
"""
            
            response = await client.chat_completion_with_retry(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì œê³µëœ ë°ì´í„°ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ì •í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                model="gpt-4o-mini",
                temperature=0.3,  # ðŸ”¥ 0.7 â†’ 0.3ìœ¼ë¡œ ë‚®ì¶¤ (ê±°ì§“ë§ ë°©ì§€)
                max_tokens=1500
            )
            
            answer = response.choices[0].message.content.strip()
            print(f"   ðŸ¤– ë‹µë³€ ìƒì„±: {answer[:100]}...")
            
            return answer
            
        except Exception as e:
            print(f"   âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{state.question}' ì§ˆë¬¸ì— ëŒ€í•œ ë¬¸ì œ í•´ê²° ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_project_links(self, selected_projects: List[str]) -> Dict[str, str]:
        """ì„ íƒëœ í”„ë¡œì íŠ¸ë“¤ì˜ ë§í¬ ìƒì„±"""
        
        links = {}
        
        for project in selected_projects:
            if project in self.project_titles:
                title = self.project_titles[project]
                links[f"ðŸ“¦ {title}"] = f"/{project}"
                print(f"   ðŸ”— ë§í¬ ìƒì„±: {title} -> /{project}")
        
        return links

async def problem_solving_agent(state: ChatState) -> ChatState:
    """Problem Solving Agent ì‹¤í–‰ í•¨ìˆ˜"""
    agent = ProblemSolvingAgent()
    return await agent.process(state)