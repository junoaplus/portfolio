# 신문 구독 서비스 이탈 예측 프로젝트

## 프로젝트 개요

디지털 전환과 미디어 경쟁 심화로 신문사 구독자 유지가 어려워지고 있는 상황에서, 머신러닝을 활용하여 신문사 고객의 이탈 가능성을 식별하고 이탈률을 낮춰 수익을 최대화하는 시스템을 개발했다.

Kaggle의 신문 구독자 이탈 데이터를 활용했다. 최종적으로 Random Forest 모델을 선정해서 87% F1-Score와 ROC AUC 0.94를 달성했고, Streamlit으로 대시보드를 구축해서 개별 고객의 이탈 가능성을 예측하고 이탈 고객 TOP 50 분석을 제공하는 시스템을 완성했다.

## 담당 역할
4명 팀에서 나는 XGBoost와 SVM 모델 구현 및 최적화, SMOTE 데이터 증강 전략 설계, Cost-Sensitive Learning 파라미터 튜닝, 프로젝트 발표 및 최종 보고서 작성을 담당했다.


## 데이터 분석 과정

Kaggle에서 제공하는 신문 구독자 이탈 데이터셋을 분석했다. 총 15,855명의 구독자 데이터에 19개의 피처가 있었는데, 구독자 중 이탈자(No)가 구독 유지자(Yes)보다 약 4배 많아서 심각한 클래스 불균형 문제가 있었다.

데이터 전처리가 가장 중요한 작업이었다. HH Income은 "$30,000 - $39,999" 같은 범위 데이터를 평균값으로 변환하고, "plus"나 "under"가 포함된 값은 전체 평균으로 대체했다. Weekly Fee도 마찬가지로 범위 데이터를 평균값으로 처리했다.

Age range는 "25-29" 같은 연령대를 평균 나이로 변환했고, Nielsen Prizm 코드를 성별(남:0, 여:1)과 근로 여부(비근로:0, 근로:1)로 분해했다. 배송 주기는 온라인 여부와 배송 일수로 나눠서 처리했다.

상관관계 분석 결과 Weekly Fee와 Delivery Period가 0.37로 가장 높은 양의 상관관계를 보였고, Year Of Residence와 Age가 0.35의 상관관계를 나타냈다. 반면 Is_Online과 Gender는 다른 변수들과 거의 무상관이었다.

EDA를 통해 발견한 인사이트들이 많았다. 주택을 소유한 고객보다 임차 고객의 이탈률이 높았고, 매일 배송을 신청한 고객이 이탈률이 가장 낮았다. 주간 요금이 낮을수록 이탈 가능성이 높았고, 나이가 많은 고객들은 구독을 유지하는 경향이 강했다.

## 기술 선택 과정

6개의 다양한 머신러닝 모델을 비교 분석했다. 로지스틱 회귀, KNN, 랜덤 포레스트, XGBoost, SVM, 다층 퍼셉트론을 각각 구현해서 성능을 비교했다.

클래스 불균형 문제 해결을 위해 Cost-Sensitive Learning을 적용했다. 각 모델에 클래스 가중치를 부여해서 소수 클래스(이탈자)에 더 높은 페널티를 주도록 설정했다.

데이터 증강을 위해 SMOTE(Synthetic Minority Oversampling Technique)를 활용했다. 기존 데이터의 분포를 유지하면서 고품질 합성 데이터를 생성해서 클래스 불균형(YES:NO = 1:4.7)을 1:1로 완전히 해결했다. SMOTE 증강 후 모든 모델의 성능이 크게 향상되었다.

하이퍼파라미터 튜닝은 GridSearchCV와 RandomizedSearchCV를 병행해서 사용했다. 각 모델별로 최적의 파라미터를 찾기 위해 교차 검증을 수행했다.

평가 지표는 클래스 불균형을 고려해서 Precision, Recall, F1-Score를 클래스별로 분석했고, ROC AUC를 주요 지표로 사용했다. 단순 Accuracy는 불균형 데이터에서 오해를 줄 수 있어서 보조 지표로만 활용했다.

## 구현 중 어려움과 문제 해결

### 1. 극심한 클래스 불균형 문제
**문제:** 신문 이탈자(NO) 대비 구독자(YES)가 4.7:1로 극심한 불균형을 보였다. 소수 클래스인 이탈자 예측이 매우 어려웠고, 단순 정확도로는 성능을 제대로 평가할 수 없었다.

**해결:** SMOTE 오버샘플링으로 고품질 합성 데이터를 생성했다. 소수 클래스의 현실적인 가구소득, 연령, 주소 패턴을 가진 데이터를 생성하여 4.7:1을 1:1 균형으로 조정했다.

### 2. 복합적 데이터 타입 처리
**문제:** 가구소득 범위($30,000-$39,999), 연령대(30-40), 주간요금($10-$15) 등 범위형 데이터를 수치형으로 변환하기 까다로웠다. "plus"나 "under"가 포함된 예외 케이스도 있었다.

**해결:** 도메인 특화 전처리 파이프라인을 구축했다. 가구소득 범위를 평균값으로 변환($30,000-$39,999→$34,999.5), 연령대 범위를 중간값으로, 배송주기를 수치형으로 매핑하는 체계적 변환을 구현했다.

### 3. 도메인 특화 전처리 복잡성
**문제:** Nielsen Prizm 그룹, 배송주기, 리워드 프로그램 등 신문업계 특화 변수들의 적절한 인코딩이 필요했다. 단순 라벨 인코딩으로는 변수 간 관계를 제대로 표현할 수 없었다.

**해결:** Nielsen Prizm 코드의 의미를 분석해서 성별과 연령대/근로상태로 분해했다. 배송주기는 일수로 매핑하고, 리워드 프로그램은 참여 여부로 이진화해서 모델이 이해하기 쉽도록 변환했다.

### 4. 6개 모델 성능 비교 전략
**문제:** 로지스틱 회귀부터 SVM까지 서로 다른 특성의 알고리즘들을 공정하게 비교할 평가 전략이 필요했다. 각 모델의 강점을 살리면서도 일관된 기준으로 평가해야 했다.

**해결:** 단순 정확도가 아닌 Precision, Recall, F1-Score를 종합 평가했다. 클래스별로 성능을 분석해서 RandomForest가 Class 0(0.87), Class 1(0.88) 모두에서 균형잡힌 성능을 확인했다.

### 5. Cost-Sensitive 파라미터 튜닝 복잡성
**문제:** 불균형 데이터에 특화된 클래스 가중치 및 임계값 최적화가 복잡했다. 각 모델마다 최적의 Cost-Sensitive 설정이 달라서 체계적인 튜닝이 어려웠다.

**해결:** GridSearchCV를 활용해 각 모델에 최적화된 class_weight와 threshold를 찾았다. class_weight='balanced'를 기본으로 하되, 모델별 특성에 맞는 추가 튜닝을 진행해서 최적 성능을 확보했다.

### 6. 비즈니스 지표 해석의 어려움
**문제:** Weekly Fee, HH Income 등이 이탈에 미치는 실질적 영향도 분석이 어려웠다. Feature Importance 수치를 비즈니스 관점에서 해석하고 실행 가능한 인사이트로 변환해야 했다.

**해결:** Feature Importance 분석을 통해 Weekly Fee(20%), HH Income(18%), Reward Program(16%)이 핵심 이탈 요인임을 확인했다. 이를 바탕으로 가격 정책 강화, 리워드 프로그램 개선 등 구체적 마케팅 전략을 제안했다.

## 성능 최적화

초기 모델들은 클래스 불균형 때문에 성능이 만족스럽지 않았다. 특히 이탈자(Class 0)의 Precision이 0.3 수준에 머물렀다.

SMOTE 데이터 증강이 게임 체인저였다. 기존 데이터의 분포를 유지하면서 고품질 합성 데이터를 생성해서 클래스 비율을 1:1로 완전히 균형 있게 조정했다. 증강 후 로지스틱 회귀의 Class 0 Precision이 0.30에서 0.82로 크게 향상되었다.

Cost-Sensitive Learning도 효과적이었다. 각 모델에 class_weight='balanced' 파라미터를 적용해서 소수 클래스에 자동으로 높은 가중치를 부여했다. 이를 통해 모델이 이탈자를 더 잘 탐지하도록 학습시켰다.

하이퍼파라미터 튜닝으로 세부 성능을 개선했다. Random Forest의 경우 n_estimators, max_depth, min_samples_split 등을 최적화해서 과적합을 방지하면서도 높은 성능을 확보했다.

교차 검증을 통해 모델의 안정성을 확인했다. StratifiedKFold로 클래스 비율을 유지하면서 검증해서 일반화 성능을 보장했다.

## 실패한 시도들

처음에는 단순하게 결측값을 제거하고 기본 모델들을 돌려봤는데 성능이 형편없었다. 정확도는 80% 넘게 나와도 실제 이탈자는 거의 찾지 못하는 문제가 있었다.

다른 오버샘플링 기법들도 시도해봤지만 SMOTE만큼 효과적이지 않았다. RandomOverSampler 같은 단순 복제 방식은 과적합을 유발했고, ADASYN은 노이즈에 민감해서 성능 향상이 제한적이었다.

앙상블 모델들을 복잡하게 조합해봤지만 단일 Random Forest보다 나은 결과를 얻지 못했다. 오히려 해석가능성만 떨어뜨리는 결과가 나왔다.

피처 엔지니어링을 과도하게 시도한 것도 실패였다. 기존 변수들을 조합해서 새로운 피처를 만들어봤지만 성능 향상보다는 과적합만 유발했다.

딥러닝 모델도 실험해봤지만 데이터 크기 대비 복잡도가 높아서 오버피팅이 심했고, 해석가능성도 떨어져서 비즈니스 활용에 부적절했다.

## 최종 결과와 배운 점

최종적으로 Random Forest 모델을 선정했다. SMOTE 데이터 증강 후 Class 0 F1-Score 0.87, Class 1 F1-Score 0.88로 균형 잡힌 성능을 보였다. ROC AUC는 0.94를 달성해서 우수한 분류 성능을 확인했다.

변수 중요도 분석에서 Weekly Fee(20%), HH Income(18%), Reward Program(16%)이 상위 3개 변수로 나타났다. 이는 가격 정책과 리워드 프로그램이 고객 이탈 방지의 핵심이라는 인사이트를 제공했다.

Streamlit으로 실용적인 대시보드를 구축했다. 개별 고객 정보를 입력하면 이탈 확률을 예측해주고, 이탈 가능성이 높은 TOP 50 고객을 분석해서 마케팅 전략 수립에 활용할 수 있도록 했다.

가장 큰 배움은 클래스 불균형 문제 해결의 중요성이었다. 단순히 정확도만 보고 모델을 평가하면 안 되고, 비즈니스 목표에 맞는 평가 지표를 선택해야 한다는 걸 깨달았다.

데이터 전처리의 중요성도 크게 느꼈다. 아무리 좋은 모델을 써도 데이터 품질이 따라주지 않으면 의미가 없다. 범위형 데이터, 결측값, 카테고리 변수를 체계적으로 처리하는 것이 성공의 열쇠였다.

SMOTE 같은 데이터 증강 기법의 효과도 인상적이었다. 실제 데이터의 분포를 유지하면서 고품질 합성 데이터를 생성해서 클래스 불균형을 해결하는 것이 다른 오버샘플링 기법보다 훨씬 효과적이었다.

비즈니스 인사이트 도출도 중요한 성과였다. 주간 요금이 낮은 고객, 리워드 프로그램에 참여하지 않은 고객, 젊은 연령층이 이탈 위험이 높다는 것을 발견해서 실질적인 마케팅 전략을 제안할 수 있었다.