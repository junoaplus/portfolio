# 보드게임 룰 챗봇 '보비(BOVI)' 프로젝트

## 프로젝트 개요

보드게임 초보자들의 게임 선택 장애와 복잡한 룰 이해를 돕기 위해 LLM 파인튜닝 챗봇과 RAG 기반 전문 AI 챗봇 시스템을 개발했다. 보드게임카페에서 실제 사용할 수 있는 실용적인 서비스를 목표로, 초기에는 GPT-4 RAG 시스템으로 서비스하면서 사용자 QA 데이터를 축적하고, 이후 EXAONE 파인튜닝 모델로 전환하는 하이브리드 전략을 구성했다.

최종적으로 AWS EC2에서 안정적으로 서비스되는 시스템을 구축했다. QR 코드로 모바일 접속이 가능하고, 커스텀 세션 관리로 추천과 룰 설명을 분리해서 각각 독립적인 대화 맥락을 유지한다.


## 담당 역할
4명 팀에서 풀스택 개발자로 참여했고, 프로젝트 총괄 및 팀 리딩, EXAONE 파인튜닝 모델 학습, 217개 게임별 FAISS 벡터DB 구축과 청킹 전략 설계, Django 웹 인터페이스 구축, AWS EC2 배포와 Nginx 웹서버 구성을 담당했다.



## 데이터 분석 과정

보드게임 룰북과 커뮤니티 데이터를 분석하니 크게 두 가지 문제가 있었다. 첫째는 보드게임 초보자들이 수백 개 게임 중에서 자신에게 맞는 게임을 찾기 어렵다는 점이고, 둘째는 게임을 선택해도 복잡한 룰을 이해하기 힘들다는 점이었다.

게임 추천과 룰 설명은 완전히 다른 검색 패턴이 필요하다는 걸 깨달았다. 게임 추천할 때는 "2-4명이 할 수 있고 30분 이내로 끝나는 전략게임"처럼 여러 게임을 비교해야 하고, 룰 설명할 때는 "이 카드를 언제 사용할 수 있나요?" 같은 특정 게임 내 세부 규칙을 정확히 찾아야 한다.

그래서 청킹 전략을 차별화했다. 게임 추천용은 217개 게임을 각각 하나의 청크로 해서 통합 벡터DB를 만들고, 룰 설명용은 각 게임마다 개별 벡터DB를 구축하되 게임 타입에 따라 청킹 방식을 달리했다. 카드게임은 카드별로, 전략게임은 턴 단위로, 보드게임은 게임 진행 단계별로 청킹해서 검색 정확도를 높였다.

파인튜닝을 위한 QA 데이터 확보 과정에서 큰 어려움이 있었다. 217개 게임 각각에 대해 1000개 이상의 고품질 질문-답변 쌍을 만들어야 했는데, 실제로는 이런 대용량 게임별 QA 데이터가 존재하지 않았다. 모든 게임에 대해 충분한 학습 데이터를 확보하는 것이 현실적으로 불가능했다.

그래서 실험적 접근법을 취했다. 먼저 '뱅(Bang!)' 게임 하나만을 대상으로 EXAONE 모델 파인튜닝을 진행했다. 1000개 QA 데이터셋과 1500개 QA 데이터셋을 각각 준비해서 데이터 크기에 따른 성능 차이를 분석했다. 각 데이터셋 크기별로 하이퍼파라미터를 조정하며 최적의 학습 설정을 찾았다. 1000개 데이터셋에서는 학습률과 배치 크기를 조정했고, 1500개 데이터셋에서는 에포크 수와 정규화 파라미터를 추가로 튜닝했다.

이런 실험을 통해 데이터 크기와 파인튜닝 성능의 관계를 파악했고, 결국 실제 사용자들이 시스템을 사용하면서 자연스럽게 QA 데이터가 축적되도록 하는 방향으로 전환했다. 모든 사용자 질문과 시스템 답변을 PostgreSQL에 자동 저장해서 향후 게임별 파인튜닝용 데이터로 활용할 수 있게 설계했다.

## 기술 선택 과정

파인튜닝 모델 선택에서 고민이 많았다. GPT-4는 성능이 좋지만 파인튜닝 비용이 비싸고, 오픈소스 모델들은 한국어 성능이 아쉬웠다. 결국 EXAONE을 선택했는데, 한국어 성능이 뛰어나고 파인튜닝 비용이 합리적이었다.

벡터 DB는 FAISS를 선택했다. Pinecone이나 Qdrant도 고려했지만, 217개 게임별로 독립적인 벡터DB를 구축해야 해서 로컬에서 완전히 제어 가능한 FAISS가 더 적합했다. 게임 선택 후 해당 게임의 벡터DB만 동적 로드하는 방식으로 메모리도 최적화할 수 있었다.

백엔드 아키텍처는 Django와 FastAPI 하이브리드로 구성했다. Django로 웹 인터페이스와 세션 관리를 하고, FastAPI로 AI 모델 서빙과 벡터 검색을 처리했다. 각 서비스가 독립적으로 초기화되고 헬스체크를 통해 한 서비스가 실패해도 다른 기능은 정상 작동하도록 격리했다.

임베딩 모델은 BGE-M3를 선택했다. 한국어에 특화된 성능을 보이는 모델이라서 보드게임 룰북의 한국어 텍스트를 더 정확하게 임베딩할 수 있었다. 보드게임 용어와 설명이 대부분 한국어로 되어 있어서 한국어 특화 임베딩 모델이 검색 정확도 향상에 중요했다.

인프라는 AWS EC2에 Ubuntu Server를 올리고 Nginx + Gunicorn으로 웹서버를 구성했다. PostgreSQL로 모든 QA 데이터를 자동 저장해서 향후 파인튜닝용 데이터를 축적하는 시스템도 구축했다.

## 구현 중 어려움과 문제 해결

### 1. 파인튜닝 데이터 부족 문제
**문제:** 217개 게임 전체에 대한 파인튜닝용 QA 데이터가 절대적으로 부족했다. 게임별로 최소 500개 이상의 고품질 QA가 필요한데, 수작업으로 만들기에는 시간이 너무 오래 걸렸다.

**해결:** 단계적 접근법을 사용했다. 먼저 '뱅(Bang!)' 게임 하나만 GPT-4로 1500개 QA 데이터를 생성해서 EXAONE 파인튜닝을 실험했다. 83.7% 정확도를 달성해서 접근법이 유효함을 확인했다. 본 시스템에서는 벡터DB로 정확한 룰을 찾아서 GPT가 답변하게 한 후, 그 모든 질문-답변을 자동으로 PostgreSQL에 저장하는 시스템을 구축했다. 사용자가 질문할 때마다 고품질 학습 데이터가 자동으로 쌓여서 향후 게임별 파인튜닝에 활용할 수 있게 만들었다.

### 2. EXAONE 모델 LangChain 미지원 문제  
**문제:** EXAONE 파인튜닝 모델이 LangChain과 호환되지 않아서 사용자별 대화 맥락 관리가 불가능했다. 멀티턴 대화에서 이전 질문을 기억하지 못하는 문제가 발생했다.

**해결:** 커스텀 세션 관리 시스템을 직접 구현했다. 사용자가 세션 요청하면 고유 세션 ID를 발급하고, 그 세션으로 모든 대화 맥락을 유지하도록 했다. 게임 추천용 세션과 룰 설명용 세션을 분리해서 각각 독립적으로 대화 히스토리를 관리하고, 40분 타임아웃으로 메모리 누수를 방지했다.

### 3. 보드게임카페 실사용을 위한 접근성 문제
**문제:** 은밀한 정보를 숨겨야 하는 게임들에서 공용 태블릿으로 룰을 질문하면 다른 플레이어들에게 전략이나 역할이 노출될 위험이 있었다. 특히 마피아류 게임에서 치명적이었다.

**해결:** QR 코드 생성 시스템을 만들어서 사용자가 개인 스마트폰으로 접속할 수 있게 구현했다. 5개 외부 IP 서비스를 순차적으로 시도해서 안정적으로 모바일 URL을 생성하도록 설계했다. 반응형 웹 디자인으로 모바일에서도 편리하게 사용할 수 있게 했다.

### 4. 대용량 벡터DB 메모리 관리 문제
**문제:** 217개 게임의 벡터DB를 모두 메모리에 로드하면 메모리 부족과 응답 지연이 발생했다. 특히 AWS EC2 인스턴스의 제한된 메모리에서는 시스템이 다운되는 경우도 있었다.

**해결:** 게임 선택 후 해당 게임의 벡터DB만 동적 로드하는 지연 로딩 방식으로 메모리 사용량을 최적화했다. 사용하지 않는 벡터DB는 자동으로 언로드하고, RunPod GPU 인스턴스를 활용해서 임베딩 성능도 향상시켰다.

### 5. 멀티서비스 백엔드 안정성 문제
**문제:** RAG 서비스, 파인튜닝 서비스, 세션 관리가 하나의 백엔드에서 동시 실행될 때 메모리나 CPU 과부하로 전체 시스템이 다운될 우려가 있었다.

**해결:** 서비스별로 독립적 초기화와 헬스체크를 구현해서 한 서비스가 실패해도 다른 기능은 정상 작동하도록 격리했다. 백그라운드에서 주기적으로 세션을 정리하는 별도 스레드를 운영해서 시스템 안정성을 확보했다.

## 성능 최적화

초기에는 벡터 검색 응답시간이 5-7초 정도 걸렸다. 실시간 채팅 경험을 위해서는 2초 이내로 단축해야 했다.

가장 먼저 한 건 벡터DB 로딩 방식 개선이었다. 모든 게임의 벡터DB를 사전 로드하는 대신 사용자가 게임을 선택할 때만 해당 벡터DB를 동적으로 로드하도록 바꿨다. 이렇게 하니 메모리 사용량이 80% 줄어들고 검색 속도도 빨라졌다.

RunPod GPU 인스턴스를 활용해서 임베딩 연산을 가속화했다. CPU 기반 임베딩에서 GPU 기반으로 바뀌니 임베딩 시간이 절반으로 줄었다.

청킹 전략 최적화도 중요했다. 게임별로 적절한 청크 크기를 찾기 위해 실험을 반복했다. 너무 작으면 맥락이 손실되고, 너무 크면 정확도가 떨어졌다. 결국 게임 타입별로 다른 청킹 전략을 적용해서 최적의 검색 정확도를 확보했다.

PostgreSQL 쿼리 최적화로 QA 데이터 저장과 조회 성능도 개선했다. 인덱싱과 배치 처리로 대량의 QA 데이터를 효율적으로 관리할 수 있게 되었다.

## 실패한 시도들

처음에는 모든 게임에 대해 즉시 파인튜닝을 시도했다. 217개 게임 전체의 파인튜닝 데이터를 한 번에 생성하려고 했는데, 시간도 너무 오래 걸리고 품질도 일정하지 않았다. GPT-4 API 비용도 감당하기 어려웠다.

단일 통합 벡터DB 아키텍처도 실패했다. 게임 추천과 룰 설명을 하나의 벡터DB로 처리하려고 했는데, 검색 패턴이 완전히 달라서 정확도가 크게 떨어졌다. 게임 추천할 때는 "전략게임" 같은 상위 개념으로 검색해야 하는데, 룰 설명할 때는 "이 카드의 효과" 같은 구체적 정보를 찾아야 해서 청킹 방식 자체가 달라야 했다.

LangChain 기반 아키텍처도 포기해야 했다. EXAONE 모델이 LangChain과 호환되지 않아서 복잡한 워크플로우 구현이 불가능했다. 결국 커스텀 시스템을 직접 구현하는 게 더 효율적이었다.

서버리스 아키텍처도 시도해봤지만 벡터DB의 특성상 적합하지 않았다. 벡터DB 로딩 시간 때문에 콜드 스타트 지연이 심각했고, 메모리 상태를 유지해야 하는데 서버리스 환경에서는 한계가 있었다.

## 최종 결과와 배운 점

최종적으로 217개 게임을 커버하는 안정적인 보드게임 룰 챗봇 시스템을 구축했다. 초기 GPT-4 RAG 서비스로 시작해서 사용자 데이터를 축적한 후 EXAONE 파인튜닝 모델로 전환하는 하이브리드 전략으로 각각의 장점을 활용할 수 있었다. QR 코드 모바일 접속 시스템으로 보드게임카페 실사용 환경을 고려한 UX를 제공했다.

모든 QA 데이터를 자동으로 PostgreSQL에 저장하는 시스템을 구축해서 사용자가 질문할 때마다 향후 파인튜닝용 고품질 데이터가 축적되도록 했다. 이는 서비스가 사용될수록 더 정확해지는 자가학습 시스템의 기반이 되었다.

가장 큰 배움은 GPT-4 RAG로 서비스하면서 데이터를 축적한 후 EXAONE 파인튜닝으로 전환하는 단계적 접근법의 효과였다. RAG로 즉시 서비스 가능하면서도 동시에 게임별 파인튜닝 데이터를 자동으로 수집할 수 있는 전략이 효과적이었다.

청킹 전략의 중요성도 크게 깨달았다. 게임별로 다른 청킹 방식이 필요하고, 사용 목적(추천 vs 룰설명)에 따라서도 청킹 전략을 다르게 가져가야 검색 정확도가 향상된다는 걸 실험으로 확인했다.

AWS 배포와 인프라 관리 경험도 소중했다. Nginx, Gunicorn, systemd를 활용한 프로덕션 환경 구축을 직접 해보면서 배포의 전반적인 과정을 이해할 수 있었다. 특히 멀티서비스 아키텍처에서 서비스 간 의존성 관리와 장애 격리의 중요성을 체감했다.