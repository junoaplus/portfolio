# 데이트 코스 추천 시스템 프로젝트

## 프로젝트 개요

대화형 AI 기반 개인맞춤 데이트 코스 추천 시스템을 개발했다. 목표는 사용자가 AI 챗봇과 자연스럽게 대화하며 MBTI, 관계단계, 예산 등을 입력하면, 3개의 전문 마이크로서비스가 협업하여 개인맞춤형 데이트 코스를 실시간 생성하는 것이었다.

서울시 25개구 89,321개 검증 장소 중에서 **검색 품질 최적화 단계**에서 151개 세분화 카테고리 기반 후보 축소와 지리공간 후보 축소를 먼저 적용한 후 벡터 유사도 검색을 통해 최적의 조합을 찾아 추천하고, 대화 맥락을 기억하여 점진적으로 더 정확한 추천을 제공하는 시스템이다.

## 담당 역할

5명 팀에서 풀스택 개발자로 참여했고, 마이크로서비스 아키텍처 설계, DB 설계, 백엔드 서버 구축, 벡터 DB 구축 및 최적화, RAG 파이프라인 구현, PySpark ETL 데이터 처리, 프론트엔드 UI/UX 개발을 담당했다.

## 대규모 데이터 처리 (ETL / Spark 전처리)

처음에 카카오, T맵, 네이버, 관광공사 4개 API에서 데이터를 수집했다. 20만 개의 원시 데이터가 있었지만 중복과 노이즈가 심각했다.

가장 먼저 한 작업은 \*\*카테고리 정제(비데이트 카테고리 제외)\*\*였다. 데이트 코스에 적합하지 않은 카테고리들을 제거해야 했다. 학원, 학교, 관공서, 병원, 약국 등 데이트와 관련 없는 카테고리들을 제외해서 20만개에서 약 15만개로 줄였다.

그 다음 PySpark를 활용해서 4개 API의 **중복 제거**를 진행했다. 업체명, 좌표, 전화번호를 조합해서 중복을 판별했는데, 같은 장소를 서로 다른 API에서 다르게 표기하는 경우가 많았다. 그래서 PySpark를 사용하여 업체명 유사도 매칭, 좌표 기반 클러스터링, 전화번호 매칭을 조합해서 다단계 중복 제거를 진행했다.

그 다음은 네이버 블로그 데이터 문제였다. 블로그 글과 실제 장소가 맞지 않는 경우가 많았다. 그래서 블로그 제목에 해당 가게 이름과 지역명이 모두 포함되지 않은 데이터는 제거했다. 예를 들어 강남에 있는 "ABC 카페" 리뷰인데 제목에 "ABC"나 "강남"이 없으면 신뢰도가 낮다고 판단해서 제외했다.

최종적으로 20만개 데이터가 **9만개의 고품질 데이터**로 정제되었다. (주의: 이 과정은 **전처리/정제 단계**이고, 아래의 검색 품질 최적화(후보 축소 + 벡터 검색)와는 별개임)

## 기술 선택 과정

벡터 DB는 후보 축소 후 검색이 생명이라고 생각한다. 단순 벡터 유사도만으로는 정확도가 떨어지기 때문에, 먼저 카테고리와 지리적 조건으로 후보를 줄인 다음 벡터 검색을 해야 성능이 극적으로 향상된다. 그래서 후보 축소와 필터링을 강력하게 지원하는 Qdrant를 선택했다. Pinecone도 고려했지만 오픈소스인 Qdrant가 비용 효율적이면서도 지리공간 데이터 처리와 복합 필터링에 특화되어 있어서 우리 프로젝트에 더 적합했다.

아키텍처는 처음에 에이전틱 시스템을 시도했다. 사용자 질문에 따라 AI가 자동으로 판단해서 추가 질문하고 추천하는 방식이었다. 그런데 에이전트가 무한 루프에 빠져서 끝없이 질문만 던지고, 예측 불가능한 응답 때문에 내가 원하는 결과가 나오지 않았다. 결국 예측 가능하고 안정적인 룰베이스 아키텍처로 전환했다.

데이터베이스는 PostgreSQL을 선택했다. JSON 읽기/쓰기가 편리해서 장소 정보와 사용자 대화 맥락을 유연하게 저장하고 조회할 수 있었다.

인프라는 비용을 최우선으로 고려했다. 돈이 없어서 저렴하면서도 성능 좋은 서비스를 찾아야 했다. 프론트엔드는 Vercel(무료 티어), 백엔드는 Ocean Digital(저렴한 VPS), 벡터 DB 마이크로서비스는 RunPod(GPU 사용 시 가격 경쟁력)으로 구성했다. 각각 독립적으로 스케일링 가능하도록 설계해서 비용 효율성과 성능을 동시에 확보했다.

임베딩 모델은 OpenAI text-embedding-3-large를 사용했다. 데이트는 감성이 핵심이다. "로맨틱한", "아늑한", "활기찬" 같은 감성의 미묘한 차이를 정확하게 벡터화해야 추천 품질이 좋아진다. text-embedding-3-large가 이런 감성적 뉘앙스를 가장 정확하게 캡처해서 선택했다.

## 구현 중 어려움과 문제 해결

### 1. 벡터 DB 검색 정확도 한계

**문제:** 단순 벡터 유사도만으로는 원하는 데이트 장소 추천에 실패했다. "강남의 로맨틱한 카페"라고 입력해도 전혀 관련 없는 장소가 나오는 경우가 많았다.

**해결:** Qdrant 벡터 검색 전에 151개 세분화 카테고리 기반 후보 축소와 반경 후보 축소를 먼저 적용했다. 카테고리로 후보를 줄이고, 지리적으로 적합한 범위 내에서 벡터 검색을 수행해서 정확도를 크게 향상시켰다.

### 2. 벡터 DB 임베딩 데이터 최적화

**문제:** 장소별 요약문구에 업체 정보나 홍보문구 등 불필요한 노이즈가 포함되어 있어서 검색 매칭 정확도가 떨어졌다.

**해결:** 벡터 임베딩 데이터를 정제해서 노이즈를 제거하고, 장소의 핵심 정보만 추출했다. 검색 매칭 정확도가 향상되고 불필요한 결과가 필터링되었다.

### 3. 멀티 API 데이터 품질 문제

**문제:** 카카오, 관광공사, T맵, 네이버 API 통합 시 중복·노이즈 데이터가 대량 발생했다. 같은 장소를 각각 다르게 표기하거나, 폐업한 가게 정보가 그대로 남아있는 경우가 많았다.

**해결:** PySpark ETL을 구축해서 20만→9만개 데이터 품질 정제와 중복 제거 자동화 파이프라인을 만들었다. 업체명 유사도 매칭, 좌표 기반 클러스터링, 전화번호 매칭을 조합해서 다단계 중복 제거를 진행했다.

### 4. 에이전트 vs 룰베이스 아키텍처 선택

**문제:** 자율 판단 에이전트 vs 예측가능한 룰베이스 사이에서 트레이드오프가 있었다. 에이전트는 유연하지만 예측 불가능하고, 룰베이스는 안정적이지만 경직되어 있었다.

**해결:** 룰베이스 아키텍처를 선택해서 예측 가능한 서비스 품질을 확보했다. 에이전트의 블랙박스 리스크를 회피하고, 데이트 추천이라는 명확한 목적에 최적화된 안정적인 서비스를 구축했다.

### 5. 벡터 DB 검색 성능 병목

**문제:** 디스크 I/O로 인한 33초 응답시간으로 실서비스가 불가능했다. 사용자가 30초 넘게 기다리면 서비스를 떠날 수밖에 없었다.

**해결:** 인메모리 처리와 병렬 검색을 도입해서 33초 → 3.4초로 90% 성능 향상을 달성했다. 실시간 사용자 경험을 구현할 수 있게 되었다.

### 6. 서버 비용 최적화

**문제:** 벡터 DB의 인메모리 특성상 상시 운영해야 하는데, 서버리스 방식과 비교했을 때 비용 딜레마가 있었다.

**해결:** 하이브리드 인프라를 구축했다. Main Service와 Place Service는 서버리스로, 벡터 DB만 상시 운영하는 방식으로 비용을 50% 절감했다.

### 7. 사용자 장소 조회 성능 한계

**문제:** 정렬/필터링 시 복잡한 조인 쿼리로 인한 응답 지연과 다중 사용자 접속 시 서버 과부하가 발생했다.

**해결:** Redis 캐싱 시스템을 도입해서 10분 주기로 데이터를 갱신하도록 했다. 실시간 응답 속도를 확보하고 동시 접속자 확장성을 보장할 수 있게 되었다.

### 8. 사용자 생성 콘텐츠 품질 관리

**문제:** 부적절하거나 스팸성 리뷰로 인한 서비스 신뢰도 저하 및 사용자 경험 악화가 발생했다.

**해결:** GPT 기반 자동 콘텐츠 검증 시스템을 구축해서 부적절 리뷰 등록을 차단하고, 사용자에게 재작성을 요청하는 방식으로 플랫폼 품질을 관리했다.

## 검색 품질 최적화 (Serving-time 후보 축소 + 벡터 검색)

초기에는 응답시간이 30초나 걸렸다. 사용자가 질문하고 30초 넘게 기다리면 누가 쓰겠냐. 프로파일링을 해보니 벡터 검색이 전체 응답시간의 80%를 차지했다.

벡터 DB 디스크 I/O 방식이 너무 오래 걸려서 인메모리로 바꾸고 병렬로 처리했다. 자주 사용되는 벡터 데이터를 메모리에 올리고 병렬 검색을 도입하니까 30초가 3.4초로 줄어들었다. 90% 성능 향상이었다.

추천 품질도 개선했다. 연애초기, 썸, 소개팅 단계에서 뼈다귀해장국이나 백다방 같은 이상한 장소를 추천해주는 문제가 있었다. 관계 단계별로 부적절한 장소를 먼저 제거한 후 추천할 수 있도록 후보 축소 로직을 구현했다.

UX 편의성도 대폭 개선했다. 유저 입장에서 모든 것을 채팅으로 입력하기 힘드니까, MBTI나 예산 같은 정형화된 정보는 선택 버튼으로 바꿔서 입력 편의성을 높였다.

날씨 기반 추천 시스템도 추가했다. 비오는 날과 맑은 날을 구분해서, 비 올 때는 야외 활동을 실내로 자동 변경하고 이동 동선의 반경도 줄여서 현실적인 추천을 제공했다.

검색 품질 최적화를 3단계로 진행했다.
1단계: 151개 세분화 **카테고리 기반 후보 축소**
2단계: 지리공간 **후보 축소**(0.8km 반경)
3단계: **벡터 검색**으로 사용자 맞춤 최적화.

## 실패한 시도들

처음에는 에이전트 시스템을 시도했다. 사용자가 질문하면 에이전트가 자율적으로 판단해서 추가 질문하고 추천하는 방식이었다. 그런데 이게 완전 재앙이었다. 무한질문 늪에 빠져서 사용자가 답변을 받기까지 10분씩 걸리는 경우도 있었다.

에이전트가 "예산은 얼마나 되시나요?", "어떤 분위기를 좋아하시나요?", "실내와 실외 중 어느 걸 선호하시나요?" 이런 식으로 질문을 끝없이 던져댔다. 예측 불가능한 응답 때문에 품질 관리도 불가능했다.

결국 룰베이스 아키텍처로 완전히 전환했다. 목적이 명확한 추천 시스템에서는 예측 가능하고 안정적인 룰베이스가 훨씬 적합했다.

단순 유사도 검색도 실패작이었다. 벡터 검색만으로는 정확도가 30%밖에 안 나왔다. 사용자 의도와 완전히 다른 결과가 나오는 경우가 너무 많았다.

## 최종 결과와 배운 점

최종적으로 서울시 전 지역을 커버하는 89,321개 검증된 장소 DB를 구축했다. 3개 마이크로서비스로 분산 처리하면서 평균 300ms 응답시간을 달성했다. PySpark ETL로 데이터 품질을 크게 개선했고, 4개 API 데이터를 성공적으로 융합했다.

가장 큰 배움은 **벡터 DB 후보 축소 전략의 중요성**이었다. 단순히 벡터 검색만 해서는 안 되고, 먼저 적절한 후보 축소를 통해 후보를 줄인 다음 벡터 검색을 해야 성능이 극적으로 향상된다는 걸 깨달았다. 151개 세분화 카테고리 후보 축소와 거리 기반 후보 축소가 프로젝트의 핵심 기술이었다.

룰베이스 vs 에이전트 선택도 중요한 교훈이었다. AI라고 해서 무조건 에이전트 시스템이 좋은 게 아니라, 사용 목적과 요구사항에 맞는 아키텍처를 선택하는 게 중요하다. 예측 가능한 서비스에는 룰베이스가 더 적합할 수 있다.

마이크로서비스 아키텍처 설계 경험도 많이 배웠다. 서비스 간 통신, 데이터 일관성, 장애 격리 등 실제 운영에서 고려해야 할 요소들을 직접 경험할 수 있었다.

---

## FAQ

**Q. 대규모 데이터 처리 경험/조건 있나요?**
**A.** 있습니다. PySpark 기반 **분산 전처리 파이프라인**을 구축해 4개 API(카카오/네이버/관광공사/T맵)에서 수집한 **20만 건**을 처리했습니다.

1. **비데이트 카테고리 제외 규칙** 적용 →
2. **중복 제거**(업체명 유사도 + 좌표 클러스터링 + 전화번호 매칭) →
   최종적으로 **9만 건**의 고품질 데이터셋을 확보했습니다. (스케줄링/재시도/로그 추적 운영)

**Q. 151개 카테고리/0.8km/벡터 검색 3단 로직은 뭐죠?**
**A.** 그건 \*\*실시간 추천 단계(Serving-time)\*\*의 **후보 축소 + 벡터 검색** 전략입니다. ETL 전처리와는 별개입니다.
