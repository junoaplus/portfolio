---
title: "PySpark"
icon: "⚡"
category: "llm"
slug: "pyspark"
---

# 내가 이해한 PySpark

PySpark의 가장 큰 강점은 병렬 처리를 효과적으로 한다는 것입니다. 여러 코어에서 동시에 작업을 처리해서 속도를 극대화할 수 있는 점이 pandas와 비교했을 때 압도적인 장점이라고 생각합니다.

특히 분산 환경에서 메모리를 나눠서 사용하기 때문에 단일 머신에서는 불가능한 대용량 데이터도 처리할 수 있습니다. Lazy Evaluation으로 연산을 최적화해서 실행하는 것도 효율성을 높여줍니다.

실제로 20만개 데이터를 9만개로 정제하는 작업에서 병렬 처리로 단일 머신보다 훨씬 빠르게 처리했습니다. 이런 병렬 처리 능력이 실제 비즈니스에서 PySpark의 진짜 가치라고 생각합니다.

# 프로젝트 활용 사례

## 데이트 코스 추천 AI 시스템
20만개 → 9만개 데이터 정제를 PySpark로 수행했습니다. 서울시 전체 POI 데이터에서 중복 제거, 좌표 정규화, 카테고리 표준화 작업을 분산 처리로 효율적으로 처리했습니다.

특히 지리공간 데이터 클러스터링과 텍스트 전처리 파이프라인을 구축하여 단일 머신으로는 수 시간 걸릴 작업을 30분 내로 단축했습니다.

# PySpark로 해결할 수 있는 문제들

## 💾 pandas 메모리 한계 문제
- **문제:** 대용량 데이터에서 pandas 메모리 오류 발생
- **해결:** 분산 처리로 메모리 한계 없이 데이터 처리

## ⚡ 대용량 데이터 처리 시간 문제
- **문제:** 단일 머신에서 오래 걸리는 대용량 데이터 처리
- **해결:** Lazy Evaluation과 병렬 처리로 처리 시간 대폭 단축

## 🔧 복잡한 데이터 정제 파이프라인
- **문제:** 중복제거, 정규화, 변환 등 복잡한 전처리 작업
- **해결:** DataFrame API와 Spark SQL로 효율적인 파이프라인 구축